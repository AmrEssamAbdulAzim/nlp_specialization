{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "from nbformat import read , write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('./notebooks/مقارنة أدوات التجذيع/Stemmers comparison.ipynb', 'r', encoding='utf-8') as f:\n",
    "    nb = read(f, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANR = re.compile('<.*?>') \n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleantext = re.sub(CLEANR, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown2html(txt):\n",
    "    ip = txt\n",
    "    if txt ==\"\":\n",
    "        return \"\"\n",
    "    elif txt.startswith('# '):\n",
    "        txt = txt.replace('# ',f'# <div class=title> ') \n",
    "    elif txt.startswith('## '):\n",
    "        txt = txt.replace('## ',f'## <div class=heading> ') \n",
    "    elif txt.startswith('### '):\n",
    "        txt = txt.replace('### ',f'### <div class=sub> ')\n",
    "    elif re.match('#+',txt):\n",
    "        txt=re.sub('#+\\ ',re.match('#+\\ ',txt)[0] + \" <div class=warn>\",txt)\n",
    "    elif re.match('\\ *\\d[-\\.].*',txt):\n",
    "        txt = re.sub('\\ *\\d[-\\.].*', \"<div class=warn> &nbsp; &nbsp; &nbsp; \" +re.match('\\ *\\d[-\\.].*',txt)[0],txt)\n",
    "        txt = re.sub('\\ +',' ',txt)\n",
    "    else:\n",
    "        txt = \"<div class=warn>\" + txt\n",
    "    txt= txt + '</div>'\n",
    "    \n",
    "    for i in re.findall('\\*\\*.*\\*\\*',txt):\n",
    "        t =  re.sub('^(\\*\\*)','<b>',i)\n",
    "        t = re.sub('(\\*\\*)$','</b>',t)\n",
    "        txt=re.sub('\\*\\*.*\\*\\*',t,txt)\n",
    "    print(txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# <div class=title>   مقارنة بين أدوات التجذيع الحاسوبية في اللّغة العربية</div>\n",
      "<div class=warn>في هذه التجربة نقارن بين بعض أدوات التجذيع المستخدمة للّغة العربية.</div>\n",
      "<div class=warn>مبدئياً ما هو التجذيع؟</div>\n",
      "<div class=warn>التجذيع هو عملية إزالة السوابق و اللواحق للحصول علي جذع مشترك بين الكلمات, يعتبر التجذيع وسيلة للحد من عدد الكلمات و الحصول علي الكلمات المتقاربة في حالة البحث. </div>\n",
      "<div class=warn>فمثلا من الطبيعي أنه إذا بحثنا عن كلمة \"الكتابات\" نجد نتائج تشمل \"الكتابة\"</div>\n",
      "<div class=warn>أما عن السوابق فهي الاجزاء التي تتصل لأول الكلمات و ليست جزء أصيل منها, مثل \"ي\" المضارعة في الأفعال, و مثل \"ال\" التعريف. و مثلها اللواحق و هي التي تلحق بالكلمة أي تلتصق بآخرها و ليست أصيلة فيها مثل \"ات\" التأنيث و غيرها.</div>\n",
      "<div class=warn>السوابق و اللّواحق يشار إليهما باللّواصق.</div>\n",
      "<div class=warn>يذكر أيضا, أن هناك لواصق بسيطة و هي التي تتكون من صورة واحدة من اللّواصق مثل في \"الباب\", و هناك لواصق معقّدة تتكون من أكثر من صورة مثل \"بالباب\", فههنا الباء و \"ال\" التعريف.</div>\n",
      "<div class=warn>اعلم أن التجذيع  وظيفة مختلفة عن التجذير و هو الوصول لأصل الكلمة الصرفي.</div>\n",
      "<div class=warn>فكلمة \"الكتابات\" و \"الكتابة\" و \"يكتب\" و \"سيكتب\" كلهم ينتمون <b>لنفس</b> الجذر \"كتب\", لكن تنتمي الكلمتان الأولتان لنفس الجذع \"كتاب\" و الأخرتان للجذع \"كتب\".</div>\n",
      "<div class=warn>في البحث نناقش:</div>\n",
      "<div class=warn> &nbsp; &nbsp; &nbsp; 1. طريقة الاستخدام</div>\n",
      "<div class=warn> &nbsp; &nbsp; &nbsp; 2. الكفاءة</div>\n",
      "<div class=warn> &nbsp; &nbsp; &nbsp; 3. السرعة </div>\n",
      "## <div class=heading>   البيانات</div>\n",
      "### <div class=sub>   قراءة البيانات</div>\n",
      "<div class=warn>مصدر الحزمة: https://github.com/motazsaad/arabic-sentiment-analysis</div>\n",
      "## <div class=heading>   المعالجات القبلية</div>\n",
      "<div class=warn>نقوم بتحميل بتحميل مسبعدات الفهرسة من مكتبةNLTK.</div>\n",
      "<div class=warn>تقوم الدوالّ التالية بإزالة التشكيل و التطويل و مستبعدات الفهرسة و المسافات المتتالية و المسافات أول الجمل و تحول التفاعلات (إيموجي) لأوصاف مكتوبة.</div>\n",
      "<div class=warn>نقوم بترتيب سلسلة الدوالّ للمعالجة القبلية, تغيير الترتيب قد يؤدي إلي نواتج مختلفة.</div>\n",
      "<div class=warn>نقوم بحفظ النص دون معالجة قبلية</div>\n",
      "<div class=warn>مراحل التغيير بعد كل دالّة</div>\n",
      "<div class=warn>لاحظ أهمية المعالجة القبلية المخصوصة علي حسب طبيعة كل حزمة, فعلي سبيل المثال النصوص من منصة تويتر مختلفة عن النصوص من الكتب مختلفة عن المدونات.</div>\n",
      "## <div class=heading>   أدوات التجذيع</div>\n",
      "<div class=warn>تجربة مبدئية لكيفية عمل كل أداة تجذيع, مع تقييم لجودة العملية.</div>\n",
      "<div class=warn>تعمل المكتبات علي مستويين علي حسب طبيعة كل أداة, الطريقة الأولي هي التجذيع علي مستوي النص, و الثانية علي مستوي الكلمة في النص.</div>\n",
      "<div class=warn>بالتالي سنقوم باختبار كل مجذّع علي أربعة أحوال:</div>\n",
      "<div class=warn> &nbsp; &nbsp; &nbsp; 1. النص المعالج</div>\n",
      "<div class=warn> &nbsp; &nbsp; &nbsp; 2. النص الغير معالج</div>\n",
      "<div class=warn> &nbsp; &nbsp; &nbsp; 3. النص كاملا</div>\n",
      "<div class=warn> &nbsp; &nbsp; &nbsp; 4. النص كمجموعة كلمات</div>\n",
      "<div class=warn>نستعامل مع أربع مكتبات توفّر خاصية التجذيع.</div>\n",
      "<div class=warn> &nbsp; &nbsp; &nbsp; 1. فراسة</div>\n",
      "<div class=warn> &nbsp; &nbsp; &nbsp; 2. تاشفين</div>\n",
      "<div class=warn> &nbsp; &nbsp; &nbsp; 3. عاصم</div>\n",
      "<div class=warn> &nbsp; &nbsp; &nbsp; 4. nltk</div>\n",
      "<div class=warn>الدالّة التالية تقوم بتطبيق الطريقة المرغوبة مع أي أداة تجذيع</div>\n",
      "### <div class=sub>   فراسة </div>\n",
      "<div class=warn>الملاحظ أن فراسة تعمل علي كلا المستويين, لكن بطيئة علي مستوي الكلمة, فراسة حولت التفاعلات (إيموجي) إلي علامات استفهام و لكن لم تمس النص الأجنبي في حالة النص المُعالج.</div>\n",
      "<div class=warn>و تعتبر جودة التجذيع عالية, فعلي سبيل المثال تحوّلت كلمة \"يهمني\" إلي \"اهم\" و \"يكفي\" إلي \"كفي\" و \"عقلانيه\" إلي \"عقلاني\" و \"يدوم\" إلي \"دام\" و لكن لم تحول \"استمرار\".</div>\n",
      "### <div class=sub>   تشافين</div>\n",
      "<div class=warn>بالنسبة لتاشفين فتعمل علي مستوي الكلمة, و تعتبر جودتها متوسطة, فكلمة \"يهمني\" تحولت إلي \"هم \"و كلمة \"يكفي\" تحولت إلي \"كفي\" و \"عقلان\" إلي عقلاني\" بينما لم تمس \"استمرار\" و أفسدت كلمة \"لحظة. </div>\n",
      "<div class=warn>يلاحظ أيضاً تستطيع التعمل مع التفاعلات (الإيموجي).</div>\n",
      "### <div class=sub>   عاصم  </div>\n",
      "<div class=warn>المصدر: https://github.com/assem-ch/arabicstemmer_pythonlibrary</div>\n",
      "<div class=warn>مكتبة عاصم تعمل علي مستوي الكلمة و أداءها في المثال يعتبر متوسط, ففي \"يهم\" و \"يكف\" أبقي علي الياء الزائدة, و نجح في استخراج كلمة \"مبسوط\" و لم يمس \"استمرار\", و أفسدت كلمات مثل \"لحظة\" </div>\n",
      "### <div class=sub>   NLTK</div>\n",
      "<div class=warn>أخيراً مكتبة nltk تعمل علي مستوي الكلمة, و تستطيع التعامل مع التفاعلات, و تعتبر الأضعف في التعامل مع المثال.</div>\n",
      "<div class=warn>فمثلاً تحولت \"استمرار\" إلي \"رار\" و \"مبسوط\" إلي \"بسط\" و \"لحظتها\" إلي \"لحظ\" و أبقت الياء الزائدة في \"يدوم\", لكن نجحت في تحويل \"الاشياء\" .</div>\n",
      "## <div class=heading>   اختبار السرعة</div>\n",
      "### <div class=sub>   تحليل الأداء</div>\n",
      "<div class=warn>نقوم هاهنا باختبار سرعة تحليل كل أداة بناءً علي حجم النص نفسه</div>\n",
      "<div class=warn>تنبيه: قمنا بتطبيق عملية حسابية علي النواتج لتوضيح الصورة.</div>\n",
      "<div class=warn>عام الأفضل من حيث السرعة.</div>\n",
      "<div class=warn>و لكن هذه النصوص تعتبر قصيره كونه مصدرها تغريدات من تويتر, ماذا إذا كنا تعامل مع نصوص طويلة ؟</div>\n",
      "<div class=warn>مع زيادة حجم النص الواحد تقاربت السرعات نسبياً, كان أداء nltk أسرع من أداء عاصم, و لم تزل فراسة صاحبة المرتبة الأخيرة من حيص السرعة لكن أداء أفضل بكثير بالنسبة للنصوص الطويلة.</div>\n",
      "## <div class=heading>   الاستنتاج</div>\n",
      "<div class=warn>يمكن القول بأن فراسة هي الأداة الأفضل في عملية التجذيع ة لكن الأبطئ من حيث السرعة, استخدامها أنسب مع الحزم الضخمة المستخدمة التي تشبه حزم ويكيبيديا, بالنسبة لمكتبتي تاشفين و عاصم فأداؤهما متوسط و سرعة الأول أفضل من الثاني لذا يمكن أن نضع عاصم في المرتبة الثانية, و يأتي nltk أخيراً بسبب فساد أكثر من جذع أثناء تجربة الجودة.</div>\n",
      "<div class=warn>بالطبع لم يمكن الحكم النهائي علي جودة الأدوات بهذه المعدودة, ة لكن يمكن يحدد كل مستخدم طبيعة الاختبار التي يراها مناسبة للتحديد.</div>\n"
     ]
    }
   ],
   "source": [
    "for i in nb['cells']:\n",
    "    if i['cell_type'] == 'markdown':\n",
    "        \n",
    "        i['source'] = cleanhtml(i['source'])\n",
    "        i['source'] = '\\n'.join([markdown2html(j) for j in i['source'].split('\\n')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('./Stemmers comparison.ipynb', 'w', encoding='utf-8') as f:\n",
    "    write(nb,f,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
