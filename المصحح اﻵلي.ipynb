{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c26980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amr/anaconda3/envs/torch/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package punkt to /home/amr/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "import collections\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from stopwordsallforms import STOPWORDS as arb_stopwords\n",
    "import elements\n",
    "#nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd66ddec",
   "metadata": {},
   "source": [
    "# Data\n",
    "### Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2830b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(t):\n",
    "    return t.translate(t.maketrans(''.join(elements.ALEF_HAMZA_FORMS+elements.NON_ALIF_HAMZA_FORMS+tuple(elements.ALIF_MAQSURA)),\"اااويي\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68066281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(text):\n",
    "    search = [\"أ\",\"إ\",\"آ\",\"ة\",\"_\",\"-\",\"/\",\".\",\"،\",\" و \",\" يا \",'\"',\"ـ\",\"'\",\"ى\",\"\\\\\",'\\n', '\\t','&quot;','?','؟','!']\n",
    "    replace = [\"ا\",\"ا\",\"ا\",\"ه\",\" \",\" \",\"\",\"\",\"\",\" و\",\" يا\",\"\",\"\",\"\",\"ي\",\"\",' ', ' ',' ',' ? ',' ؟ ',' ! ']\n",
    "    \n",
    "    #remove tashkeel\n",
    "    p_tashkeel = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n",
    "    text = re.sub(p_tashkeel,\"\", text)\n",
    "    \n",
    "    #remove longation\n",
    "    p_longation = re.compile(r'(.)\\1+')\n",
    "    subst = r\"\\1\\1\"\n",
    "    text = re.sub(p_longation, subst, text)\n",
    "    \n",
    "    text = text.replace('وو', 'و')\n",
    "    text = text.replace('يي', 'ي')\n",
    "    text = text.replace('اا', 'ا')\n",
    "    \n",
    "    for i in range(0, len(search)):\n",
    "        text = text.replace(search[i], replace[i])\n",
    "    \n",
    "    #trim    \n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b39cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "arb_stopwords = [clean_str(normalization(i)) for  i in set(arb_stopwords.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2802b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(t,stop=arb_stopwords):\n",
    "    return ' '.join([word for word in word_tokenize(t) if word not in stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4648ab6",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1bff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= np.load('../translation project/AD_NMT-master/LAV-MSA-2-both.pkl',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c6c699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['لا انا بعرف وحدة راحت ع فرنسا و معا شنتا حطت فيها الفرش',\n",
       " 'لا اعرف واحدة ذهبت الى فرنسا و لها غرفة و ضعت فيها الافرشة']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0] # lav , msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2325e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only msa text\n",
    "msa=[]\n",
    "for i,ex in enumerate(data):\n",
    "    msa_text = stopwords_removal(clean_str(normalization(ex[1])))\n",
    "    data[i][1] = msa_text\n",
    "    msa.append(msa_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a93c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = ' '.join(msa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb9b2e",
   "metadata": {},
   "source": [
    "Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85f0b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_d=collections.Counter(msa.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cd9b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef7c5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2msa = np.array([word for word,freq in msa_d.items() if freq > min_count ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28f48369",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa2idx = {word:i for i,word in enumerate(idx2msa)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e7b71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_data = [' '.join([i for i in t[1].split() if (msa2idx.get(i,-1) != -1)]) for t in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cfdecf",
   "metadata": {},
   "source": [
    "Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1029c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = gensim.models.Word2Vec.load('../resources/models/word vectors/word2vec/wiki/full_grams_cbow_100_wiki/full_grams_cbow_100_wiki.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28d6d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(elements.BASIC_LETTERS)\n",
    "i2v = {}\n",
    "for letter in i2l:\n",
    "    i2v[i] = t_model.wv.get_vector(letter)\n",
    "i2l +=  ' '\n",
    "l2i = {v:i for i,v in enumerate(i2l)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904d2f5",
   "metadata": {},
   "source": [
    "Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e861bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "732bb044",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-7a39153acd60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "np.random.choice(,2,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dd77b08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8a37ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(txt):\n",
    "    noise_sz = np.random.randint(0,len(txt),1)\n",
    "    replace_idx = np.random.choice(len(txt),noise_sz,replace=False)\n",
    "    letters_idx = np.random.choice(len(i2l),noise_sz,replace=False)\n",
    "    txt = list(txt)\n",
    "    for rep,let in zip(replace_idx,letters_idx):\n",
    "        txt[rep] = i2l[let]\n",
    "    return ''.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e87cbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class arrDs(Dataset):\n",
    "    def __init__(self,txt_list,l2i):\n",
    "        self.data = txt_list\n",
    "        self.l2i = l2i\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        X = noise(self.data[idx])\n",
    "        Y = self.data[idx]\n",
    "        \n",
    "        X = torch.tensor([self.l2i[i] for i in X])\n",
    "        Y = torch.tensor([self.l2i[i] for i in Y])\n",
    "        #numerilize\n",
    "        return torch.stack([X,Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "436a140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = arrDs(msa_data,l2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "09f0bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds,batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a858d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0987b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "?pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d7224b56",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [2, 31] at entry 0 and [2, 15] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-26c3503426c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [2, 31] at entry 0 and [2, 15] at entry 1"
     ]
    }
   ],
   "source": [
    "for i in dl:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e91738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
