{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c26980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amr/anaconda3/envs/torch/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "import collections\n",
    "import pyarabic.araby as araby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd66ddec",
   "metadata": {},
   "source": [
    "# Data\n",
    "### Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2830b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(t):\n",
    "    t = araby.strip_tashkeel(t)\n",
    "    t = araby.normalize_hamza(t)\n",
    "    t = araby.normalize_alef(t)\n",
    "    t = araby.strip_tatweel(t)\n",
    "    t = araby.normalize_teh(t)\n",
    "    t = re.sub(\"ى\",\"ي\",t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4648ab6",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1bff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= np.load('../translation project/AD_NMT-master/LAV-MSA-2-both.pkl',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c6c699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['لا انا بعرف وحدة راحت ع فرنسا و معا شنتا حطت فيها الفرش',\n",
       " 'لا اعرف واحدة ذهبت الى فرنسا و لها غرفة و ضعت فيها الافرشة']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0] # lav , msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2325e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only msa text\n",
    "msa=[]\n",
    "for i,ex in enumerate(data):\n",
    "    msa_text = normalization(ex[1])\n",
    "    data[i][1] = msa_text\n",
    "    msa.append(msa_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a93c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = ' '.join(msa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb9b2e",
   "metadata": {},
   "source": [
    "Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f0b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_d=collections.Counter(msa.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cd9b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef7c5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2msa = np.array([word for word,freq in msa_d.items() if freq > min_count ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28f48369",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa2idx = {word:i for i,word in enumerate(idx2msa)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e7b71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_data = [' '.join([i for i in t[1].split() if (msa2idx.get(i,-1) != -1 and t[1] != '')]) for t in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fa4acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_data = [i.replace('','') for i in msa_data if i != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cfdecf",
   "metadata": {},
   "source": [
    "Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1029c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = gensim.models.Word2Vec.load('../resources/models/word vectors/word2vec/wiki/full_grams_cbow_100_wiki/full_grams_cbow_100_wiki.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "28d6d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2l = list(set(normalization(araby.LETTERS)))\n",
    "i2v = {}\n",
    "for index,letter in enumerate(i2l):\n",
    "    if letter in t_model.wv.index_to_key :\n",
    "        i2v[index] = t_model.wv.get_vector(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dc4777a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2v.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3c0694af",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2l.append(' ')\n",
    "#i2l.append('')\n",
    "i2l.append('X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef9d2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2i = {v:i for i,v in enumerate(i2l)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904d2f5",
   "metadata": {},
   "source": [
    "Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e861bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a013086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8a37ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(txt):\n",
    "    noise_sz = np.random.randint(0,len(txt),1)\n",
    "    replace_idx = np.random.choice(len(txt),noise_sz,replace=False)\n",
    "    letters_idx = np.random.choice(len(i2l),noise_sz,replace=True)\n",
    "    txt = list(txt)\n",
    "    for rep,let in zip(replace_idx,letters_idx):\n",
    "        txt[rep] = i2l[let]\n",
    "    return ''.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e87cbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class arrDs(Dataset):\n",
    "    def __init__(self,txt_list,l2i):\n",
    "        self.data = txt_list\n",
    "        self.l2i = l2i\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        X = noise(self.data[idx])\n",
    "        Y = self.data[idx]\n",
    "        \n",
    "        X = torch.tensor([self.l2i.get(i,30) for i in X])\n",
    "        Y = torch.tensor([self.l2i.get(i,30) for i in Y])\n",
    "        #numerilize\n",
    "        return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "63302423",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data, val_data = msa_data[:int(0.8*len(msa_data))],msa_data[int(0.8*len(msa_data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "436a140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds,val_ds = arrDs(trn_data,l2i),arrDs(val_data,l2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4dda7660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    label  = [i for _,i in data]\n",
    "    label = pad_sequence(label,batch_first=True)\n",
    "    data = [i for i,_ in data]\n",
    "    data = pad_sequence(data,batch_first=True)\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "09f0bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds,batch_size=4,collate_fn=collate_fn)\n",
    "val_dl = DataLoader(val_ds,batch_size=4,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0abb8f5",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d34c2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c6906af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autocorrect(nn.Module):\n",
    "    def __init__(self,num_emb,vs,hs,bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_emb,vs)\n",
    "        self.gru = nn.GRU(vs,hs,num_layers=2,bidirectional=bidirectional,batch_first=True)\n",
    "        self.lin = nn.Linear(2*hs if bidirectional == True else hs,num_emb)\n",
    "    def forward(self,x):\n",
    "        bs,seq_len=x.shape\n",
    "        x = self.emb(x)\n",
    "        x,_ = self.gru(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.lin(x)\n",
    "        return torch.softmax(x,dim=-1).view(bs*seq_len,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "af211677",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_emb = len(i2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d189c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autocorrect(num_emb,100,128).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d685d172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-2.0347,  0.3087, -2.3566,  ...,  0.3500, -0.1091,  0.2543],\n",
       "        [-0.7845,  0.8250,  0.5404,  ..., -3.3356,  1.9303,  0.4786],\n",
       "        [-0.8951,  1.9891, -2.1849,  ...,  0.0729,  0.0684,  5.5708],\n",
       "        ...,\n",
       "        [-2.0458,  0.2678, -2.0031,  ...,  1.6643,  1.2496, -1.9677],\n",
       "        [ 0.3824,  0.4593,  2.9516,  ..., -0.6370, -0.6974,  1.7829],\n",
       "        [ 0.3815, -1.6622,  0.0140,  ...,  0.1231, -0.5392,  0.4025]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load available vectors\n",
    "model.emb.weight.requires_grad_(False)\n",
    "for i in i2v.keys():\n",
    "    model.emb.weight[i] = nn.Parameter(torch.from_numpy(i2v[i])).requires_grad_(False)\n",
    "model.emb.weight.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bd5d1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7b05d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1eaa06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model,trn_dl,val_dl,loss_fnc):\n",
    "    model.train()\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        for batch in trn_dl:\n",
    "            opt.zero_grad()\n",
    "            ip,label = batch\n",
    "            op = model(ip.cuda())\n",
    "            trn_l = loss_fnc(op,label.view(-1).cuda())\n",
    "            trn_l.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in val_dl:\n",
    "                ip,label = batch\n",
    "                op = model(ip.cuda())\n",
    "                val_loss = loss_fnc(op,label.view(-1).cuda())\n",
    "        print('train_ loss ->',trn_l.item() , 'val_loss ->',val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b06cff7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ loss -> 2.9865188598632812 val_loss -> 3.298280954360962\n",
      "train_ loss -> 2.9467990398406982 val_loss -> 2.7887275218963623\n",
      "train_ loss -> 2.875417947769165 val_loss -> 2.9136877059936523\n",
      "train_ loss -> 2.90619158744812 val_loss -> 2.7545876502990723\n",
      "train_ loss -> 2.9010863304138184 val_loss -> 2.7453982830047607\n"
     ]
    }
   ],
   "source": [
    "train(5,model,trn_dl,val_dl,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9fffdbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = next(iter(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8bab5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in d:\n",
    "    sent = []\n",
    "    for j in i:\n",
    "        sent.append([i2l[k] for k in j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "34da175e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['س',\n",
       "  'ا',\n",
       "  'ع',\n",
       "  'و',\n",
       "  'د',\n",
       "  ' ',\n",
       "  'ي',\n",
       "  'ا',\n",
       "  ' ',\n",
       "  'س',\n",
       "  'ا',\n",
       "  'ر',\n",
       "  'ه',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك'],\n",
       " ['ع',\n",
       "  'ن',\n",
       "  'د',\n",
       "  'م',\n",
       "  'ا',\n",
       "  ' ',\n",
       "  'ت',\n",
       "  'ذ',\n",
       "  'ك',\n",
       "  'ر',\n",
       "  'ت',\n",
       "  ' ',\n",
       "  'ك',\n",
       "  'د',\n",
       "  'ت',\n",
       "  ' ',\n",
       "  'ا',\n",
       "  'ب',\n",
       "  'ك',\n",
       "  'ي',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك'],\n",
       " ['ه',\n",
       "  'ل',\n",
       "  ' ',\n",
       "  'ا',\n",
       "  'ن',\n",
       "  'ت',\n",
       "  ' ',\n",
       "  'ب',\n",
       "  'خ',\n",
       "  'ي',\n",
       "  'ر',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك',\n",
       "  'ك'],\n",
       " ['ل',\n",
       "  'ق',\n",
       "  'د',\n",
       "  ' ',\n",
       "  'ا',\n",
       "  'ص',\n",
       "  'ب',\n",
       "  'ح',\n",
       "  'ت',\n",
       "  ' ',\n",
       "  'ا',\n",
       "  'ل',\n",
       "  'د',\n",
       "  'ر',\n",
       "  'ا',\n",
       "  'س',\n",
       "  'ه',\n",
       "  ' ',\n",
       "  'ف',\n",
       "  'ي',\n",
       "  ' ',\n",
       "  'و',\n",
       "  'ق',\n",
       "  'ت',\n",
       "  'ن',\n",
       "  'ا',\n",
       "  ' ',\n",
       "  'ا',\n",
       "  'ل',\n",
       "  'ح',\n",
       "  'ا',\n",
       "  'ل',\n",
       "  'ي',\n",
       "  ' ',\n",
       "  'ص',\n",
       "  'ع',\n",
       "  'ب',\n",
       "  'ه',\n",
       "  ' ',\n",
       "  'ج',\n",
       "  'د',\n",
       "  'ا']]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af02279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
