{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "befc8415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "import collections\n",
    "import pyarabic.araby as araby\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c4e467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc2bf1",
   "metadata": {},
   "source": [
    "# Data\n",
    "### Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26537c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(t):\n",
    "    t = araby.strip_tashkeel(t)\n",
    "    t = araby.normalize_hamza(t)\n",
    "    t = araby.normalize_alef(t)\n",
    "    t = araby.strip_tatweel(t)\n",
    "    t = araby.normalize_teh(t)\n",
    "    t = re.sub(\"ى\",\"ي\",t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d96d55",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b86867",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= np.load('../translation project/AD_NMT-master/LAV-MSA-2-both.pkl',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99a4afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['لا انا بعرف وحدة راحت ع فرنسا و معا شنتا حطت فيها الفرش',\n",
       " 'لا اعرف واحدة ذهبت الى فرنسا و لها غرفة و ضعت فيها الافرشة']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0] # lav , msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cddb96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only msa text\n",
    "msa=[]\n",
    "for i,ex in enumerate(data):\n",
    "    msa_text = normalization(ex[1])\n",
    "    data[i][1] = msa_text\n",
    "    msa.append(msa_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d9822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = ' '.join(msa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f95f19",
   "metadata": {},
   "source": [
    "Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d3e1370",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_d=collections.Counter(msa.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2702c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dffed24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2msa = np.array([word for word,freq in msa_d.items() if freq > min_count ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08c5478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa2idx = {word:i for i,word in enumerate(idx2msa)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8da03fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_data = [' '.join([i for i in t[1].split() if (msa2idx.get(i,-1) != -1 and t[1] != '')]) for t in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "416310f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_data = [i for i in msa_data if i != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f26392f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(i) for i in msa.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cde2fa0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.8950e+03, 1.9324e+04, 0.0000e+00, 2.4495e+04, 0.0000e+00,\n",
       "        2.6011e+04, 2.0113e+04, 0.0000e+00, 1.1975e+04, 0.0000e+00,\n",
       "        6.5210e+03, 1.9170e+03, 0.0000e+00, 4.9600e+02, 0.0000e+00,\n",
       "        2.2600e+02, 6.2000e+01, 0.0000e+00, 1.1000e+01, 5.0000e+00]),\n",
       " array([ 1. ,  1.6,  2.2,  2.8,  3.4,  4. ,  4.6,  5.2,  5.8,  6.4,  7. ,\n",
       "         7.6,  8.2,  8.8,  9.4, 10. , 10.6, 11.2, 11.8, 12.4, 13. ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQRklEQVR4nO3df6zddX3H8edrrTh/jiJdw9pml2jjUsks2EA3lsXJhALGYmIMZIPOMWti2XAxmcX9gVFZajZ1I1OWKpWSMSpBDI1Ua9ORGJOBvSABCrLeYJF2hV4tghmJru69P86nyVm5tz33nNt77oXnIzk53/P+fj/f8/4kt33d749zbqoKSdIr268NuwFJ0vAZBpIkw0CSZBhIkjAMJEnA/GE30K/TTz+9RkZGht2GJM0pDzzwwE+qauGx9TkbBiMjI4yOjg67DUmaU5I8NVHd00SSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgSWIOfwJZM2dkwz19j9238dJp7ETSyeKRgSTJMJAkGQaSJAwDSRI9hEGSpUnuTfJYkj1Jrm31TyY5kOSh9rika8x1ScaSPJHkoq766lYbS7Khq35mkvtb/WtJTpnuiUqSJtfLkcER4GNVtRxYBaxPsryt+0JVrWiP7QBt3eXA24DVwJeSzEsyD/gicDGwHLiiaz+fbft6C/AccPU0zU+S1IMThkFVHayqB9vyz4HHgcXHGbIG2FpVv6iqHwFjwLntMVZVT1bVL4GtwJokAd4F3NnGbwEu63M+kqQ+TOmaQZIR4Gzg/la6JsnDSTYnWdBqi4Gnu4btb7XJ6m8CflZVR46pT/T+65KMJhkdHx+fSuuSpOPoOQySvB74OvDRqnoBuAl4M7ACOAh87mQ02K2qNlXVyqpauXDhS/6EpySpTz19AjnJq+gEwW1VdRdAVT3btf7LwDfbywPA0q7hS1qNSeo/BU5NMr8dHXRvL0maAb3cTRTgZuDxqvp8V/2Mrs3eBzzalrcBlyd5dZIzgWXA94HdwLJ259ApdC4yb6uqAu4F3t/GrwXuHmxakqSp6OXI4HzgSuCRJA+12ifo3A20AihgH/BhgKrak+QO4DE6dyKtr6pfASS5BtgBzAM2V9Wetr+PA1uTfAb4AZ3w0TH8jiBJJ8sJw6CqvgdkglXbjzPmBuCGCerbJxpXVU/SudtIkjQEfgJZkmQYSJIMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEmihzBIsjTJvUkeS7InybWtflqSnUn2tucFrZ4kNyYZS/JwknO69rW2bb83ydqu+juSPNLG3JgkJ2OykqSJ9XJkcAT4WFUtB1YB65MsBzYAu6pqGbCrvQa4GFjWHuuAm6ATHsD1wHnAucD1RwOkbfOhrnGrB5+aJKlXJwyDqjpYVQ+25Z8DjwOLgTXAlrbZFuCytrwGuLU67gNOTXIGcBGws6oOV9VzwE5gdVv3xqq6r6oKuLVrX5KkGTB/KhsnGQHOBu4HFlXVwbbqGWBRW14MPN01bH+rHa++f4K6XgZGNtzT99h9Gy+dxk4kHU/PF5CTvB74OvDRqnqhe137jb6mubeJeliXZDTJ6Pj4+Ml+O0l6xegpDJK8ik4Q3FZVd7Xys+0UD+35UKsfAJZ2DV/SaserL5mg/hJVtamqVlbVyoULF/bSuiSpB73cTRTgZuDxqvp816ptwNE7gtYCd3fVr2p3Fa0Cnm+nk3YAFyZZ0C4cXwjsaOteSLKqvddVXfuSJM2AXq4ZnA9cCTyS5KFW+wSwEbgjydXAU8AH2rrtwCXAGPAi8EGAqjqc5NPA7rbdp6rqcFv+CHAL8BrgW+0hSZohJwyDqvoeMNl9/xdMsH0B6yfZ12Zg8wT1UeCsE/UiSTo5pnQ3kbw7RtLLk19HIUkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAk0UMYJNmc5FCSR7tqn0xyIMlD7XFJ17rrkowleSLJRV311a02lmRDV/3MJPe3+teSnDKdE5QknVgvRwa3AKsnqH+hqla0x3aAJMuBy4G3tTFfSjIvyTzgi8DFwHLgirYtwGfbvt4CPAdcPciEJElTd8IwqKrvAod73N8aYGtV/aKqfgSMAee2x1hVPVlVvwS2AmuSBHgXcGcbvwW4bGpTkCQNapBrBtckebidRlrQaouBp7u22d9qk9XfBPysqo4cU59QknVJRpOMjo+PD9C6JKlbv2FwE/BmYAVwEPjcdDV0PFW1qapWVtXKhQsXzsRbStIrwvx+BlXVs0eXk3wZ+GZ7eQBY2rXpklZjkvpPgVOTzG9HB93bS5JmSF9HBknO6Hr5PuDonUbbgMuTvDrJmcAy4PvAbmBZu3PoFDoXmbdVVQH3Au9v49cCd/fTkySpfyc8MkhyO/BO4PQk+4HrgXcmWQEUsA/4MEBV7UlyB/AYcARYX1W/avu5BtgBzAM2V9We9hYfB7Ym+QzwA+Dm6ZqcJKk3JwyDqrpigvKk/2FX1Q3ADRPUtwPbJ6g/SeduI0nSkPgJZEmSYSBJMgwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJLo4c9eSnPVyIZ7+h67b+Ol09iJNPt5ZCBJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CSRA9hkGRzkkNJHu2qnZZkZ5K97XlBqyfJjUnGkjyc5JyuMWvb9nuTrO2qvyPJI23MjUky3ZOUJB1fL0cGtwCrj6ltAHZV1TJgV3sNcDGwrD3WATdBJzyA64HzgHOB648GSNvmQ13jjn0vSdJJdsIwqKrvAoePKa8BtrTlLcBlXfVbq+M+4NQkZwAXATur6nBVPQfsBFa3dW+sqvuqqoBbu/YlSZoh/V4zWFRVB9vyM8CitrwYeLpru/2tdrz6/gnqE0qyLsloktHx8fE+W5ckHWvgC8jtN/qahl56ea9NVbWyqlYuXLhwJt5Skl4R+g2DZ9spHtrzoVY/ACzt2m5Jqx2vvmSCuiRpBvUbBtuAo3cErQXu7qpf1e4qWgU8304n7QAuTLKgXTi+ENjR1r2QZFW7i+iqrn1JkmbICf8GcpLbgXcCpyfZT+euoI3AHUmuBp4CPtA23w5cAowBLwIfBKiqw0k+Dexu232qqo5elP4InTuWXgN8qz0kSTPohGFQVVdMsuqCCbYtYP0k+9kMbJ6gPgqcdaI+JEknj59AliQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJKA+cNuQHq5GdlwT99j9228dBo7kXrnkYEkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkMWAYJNmX5JEkDyUZbbXTkuxMsrc9L2j1JLkxyViSh5Oc07WftW37vUnWDjYlSdJUTceRwR9V1YqqWtlebwB2VdUyYFd7DXAxsKw91gE3QSc8gOuB84BzgeuPBogkaWacjNNEa4AtbXkLcFlX/dbquA84NckZwEXAzqo6XFXPATuB1SehL0nSJAYNgwK+k+SBJOtabVFVHWzLzwCL2vJi4OmusftbbbL6SyRZl2Q0yej4+PiArUuSjhr0i+r+oKoOJPlNYGeSH3avrKpKUgO+R/f+NgGbAFauXNn3fgf5IjFJejka6Migqg6050PAN+ic83+2nf6hPR9qmx8AlnYNX9Jqk9UlSTOk7zBI8rokbzi6DFwIPApsA47eEbQWuLstbwOuancVrQKeb6eTdgAXJlnQLhxf2GqSpBkyyGmiRcA3khzdz79V1beT7AbuSHI18BTwgbb9duASYAx4EfggQFUdTvJpYHfb7lNVdXiAviRJU9R3GFTVk8DbJ6j/FLhggnoB6yfZ12Zgc7+9SJIG4yeQJUmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCQxwN9AljT9RjbcM9D4fRsvnaZO9ErjkYEkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEn4dRSSmkG+CsOvwZj7Zs2RQZLVSZ5IMpZkw7D7kaRXkllxZJBkHvBF4N3AfmB3km1V9dhwO5N0snlEMjvMijAAzgXGqupJgCRbgTWAYSBpUn7L6/RJVQ27B5K8H1hdVX/RXl8JnFdV1xyz3TpgXXv5VuCJGW10ak4HfjLsJqaJc5l9Xi7zAOcy0367qhYeW5wtRwY9qapNwKZh99GLJKNVtXLYfUwH5zL7vFzmAc5ltpgtF5APAEu7Xi9pNUnSDJgtYbAbWJbkzCSnAJcD24bckyS9YsyK00RVdSTJNcAOYB6wuar2DLmtQc2J01k9ci6zz8tlHuBcZoVZcQFZkjRcs+U0kSRpiAwDSZJhMN2SLE1yb5LHkuxJcu2wexpEknlJfpDkm8PuZRBJTk1yZ5IfJnk8ye8Nu6d+Jfnr9rP1aJLbk/z6sHvqVZLNSQ4lebSrdlqSnUn2tucFw+yxV5PM5e/bz9jDSb6R5NQhtjglhsH0OwJ8rKqWA6uA9UmWD7mnQVwLPD7sJqbBPwHfrqrfAd7OHJ1TksXAXwErq+osOjdcXD7crqbkFmD1MbUNwK6qWgbsaq/nglt46Vx2AmdV1e8C/wlcN9NN9cswmGZVdbCqHmzLP6fzn87i4XbVnyRLgEuBrwy7l0Ek+Q3gD4GbAarql1X1s6E2NZj5wGuSzAdeC/zXkPvpWVV9Fzh8THkNsKUtbwEum8me+jXRXKrqO1V1pL28j85npuYEw+AkSjICnA3cP+RW+vWPwN8A/zvkPgZ1JjAOfLWd8vpKktcNu6l+VNUB4B+AHwMHgeer6jvD7Wpgi6rqYFt+Blg0zGam0Z8D3xp2E70yDE6SJK8Hvg58tKpeGHY/U5XkPcChqnpg2L1Mg/nAOcBNVXU28N/MnVMR/087n76GTsD9FvC6JH863K6mT3XudZ/z97sn+Vs6p4xvG3YvvTIMToIkr6ITBLdV1V3D7qdP5wPvTbIP2Aq8K8m/Drelvu0H9lfV0SO0O+mEw1z0x8CPqmq8qv4HuAv4/SH3NKhnk5wB0J4PDbmfgST5M+A9wJ/UHPogl2EwzZKEzrnpx6vq88Pup19VdV1VLamqEToXKP+9qubkb6BV9QzwdJK3ttIFzN2vR/8xsCrJa9vP2gXM0YvhXbYBa9vyWuDuIfYykCSr6ZxafW9VvTjsfqbCMJh+5wNX0vlN+qH2uGTYTYm/BG5L8jCwAvi74bbTn3Z0cyfwIPAInX/Dc+YrEJLcDvwH8NYk+5NcDWwE3p1kL50jn43D7LFXk8zln4E3ADvbv/1/GWqTU+DXUUiSPDKQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkAf8H6EOfug5iZJ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lengths,bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877d82bd",
   "metadata": {},
   "source": [
    "Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7be422c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = gensim.models.Word2Vec.load('../resources/models/word vectors/word2vec/wiki/full_grams_cbow_100_wiki/full_grams_cbow_100_wiki.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c257a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2l = list(set(normalization(araby.LETTERS)))\n",
    "i2v = {}\n",
    "for index,letter in enumerate(i2l):\n",
    "    if letter in t_model.wv.index_to_key :\n",
    "        i2v[index] = t_model.wv.get_vector(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d742d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2l.append(' ')#Space\n",
    "i2l.append('s')#eos\n",
    "i2l.append('E')#Empty\n",
    "i2l.append('L')#left pad\n",
    "i2l.append('R')#right pad\n",
    "i2l.append('X')#UNK\n",
    "i2l.append('P')#pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ba0780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2i = {v:i for i,v in enumerate(i2l)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcf9387f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(i2l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f0c783",
   "metadata": {},
   "source": [
    "## ALL in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "437f9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c325987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e7b6c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(txt):\n",
    "    sz = 2#int(len(txt)*0.2)\n",
    "    noise_sz = np.random.randint(0,sz if sz>1 else 1,1)\n",
    "    replace_idx = np.random.choice(len(txt),noise_sz,replace=False)\n",
    "    letters_idx = np.random.choice(len(i2l)-3,noise_sz,replace=True)\n",
    "    txt = list(txt)\n",
    "    for rep,let in zip(replace_idx,letters_idx):\n",
    "        txt[rep] = i2l[let]\n",
    "    return ''.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "752c7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class arrDs(Dataset):\n",
    "    def __init__(self,txt_list,l2i):\n",
    "        self.data = txt_list\n",
    "        self.l2i = l2i\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        X = noise(self.data[idx])\n",
    "        Y = self.data[idx]\n",
    "        \n",
    "        X = torch.tensor([self.l2i.get(i,31) for i in X])\n",
    "        Y = torch.tensor([self.l2i.get(i,31) for i in Y])\n",
    "        #numerilize\n",
    "        return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e981ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data, val_data = msa_grams[:int(0.8*len(msa_grams))],msa_grams[int(0.8*len(msa_grams)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f11696ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds,val_ds = arrDs(trn_data,l2i),arrDs(val_data,l2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49e6821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    label  = [i for _,i in data]\n",
    "    label = pad_sequence(label,batch_first=True,padding_value=l2i['P'])\n",
    "    data = [i for i,_ in data]\n",
    "    data = pad_sequence(data,batch_first=True,padding_value=l2i['P'])\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c5a29ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds,batch_size=512,collate_fn=collate_fn,drop_last=False,shuffle=True)\n",
    "val_dl = DataLoader(val_ds,batch_size=512,collate_fn=collate_fn,drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a543e5",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1df76d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cd0b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autocorrect(nn.Module):\n",
    "    def __init__(self,num_emb,vs,hs,bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_emb,vs)\n",
    "        self.gru = nn.GRU(vs,hs,num_layers=3,bidirectional=bidirectional,batch_first=True,dropout=0.2)\n",
    "        self.lin = nn.Sequential(nn.Linear(2*hs if bidirectional == True else hs,hs),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(hs,num_emb))\n",
    "    def forward(self,x):\n",
    "        bs,seq_len=x.shape\n",
    "        x = torch.relu(self.emb(x))\n",
    "        x,_ = self.gru(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.lin(x)\n",
    "        return torch.log_softmax(x,dim=-1).view(bs*seq_len,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c668a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_emb = len(i2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0acdfa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = autocorrect(num_emb,100,512).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89cd1bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load available vectors\n",
    "model.emb.weight.requires_grad_(False)\n",
    "for i in i2v.keys():\n",
    "    model.emb.weight[i] = nn.Parameter(torch.from_numpy(i2v[i].copy())).requires_grad_(False)\n",
    "model.emb.weight.requires_grad_(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "509de7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "448eb521",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(ignore_index=l2i['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "397cc787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model,trn_dl,val_dl,loss_fnc):\n",
    "    model.train()\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        for batch in tqdm.tqdm(trn_dl,desc='train'):\n",
    "            opt.zero_grad()\n",
    "            ip,label = batch\n",
    "            op = model(ip.cuda())\n",
    "            trn_l = loss_fnc(op,label.view(-1).cuda())\n",
    "            trn_l.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in tqdm.tqdm(val_dl,desc='validation'):\n",
    "                ip,label = batch\n",
    "                op = model(ip.cuda())\n",
    "                val_loss = loss_fnc(op,label.view(-1).cuda())\n",
    "        print('train_loss ->',trn_l.item() , 'val_loss ->',val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ac02cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 721/721 [01:13<00:00,  9.75it/s]\n",
      "validation: 100%|██████████| 181/181 [00:09<00:00, 19.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 0.20039041340351105 val_loss -> 0.1697191298007965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 721/721 [01:15<00:00,  9.55it/s]\n",
      "validation: 100%|██████████| 181/181 [00:09<00:00, 19.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 0.1858951300382614 val_loss -> 0.11031968891620636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 721/721 [01:14<00:00,  9.64it/s]\n",
      "validation: 100%|██████████| 181/181 [00:09<00:00, 19.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 0.16917631030082703 val_loss -> 0.12228929996490479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 721/721 [01:14<00:00,  9.64it/s]\n",
      "validation: 100%|██████████| 181/181 [00:09<00:00, 19.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 0.15981334447860718 val_loss -> 0.07429787516593933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(4,model,trn_dl,val_dl,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd517103",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip,label = batch\n",
    "op = model(ip.cuda())\n",
    "val_loss = loss_fnc(op.argmax(dim=-1),label.view(-1).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c7becfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 8, 36])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.view(512,-1,36).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "617ceed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|██████████| 181/181 [00:09<00:00, 19.50it/s]\n"
     ]
    }
   ],
   "source": [
    "t=0\n",
    "total=0\n",
    "for batch in tqdm.tqdm(val_dl,desc='validation'):\n",
    "    ip,label = batch\n",
    "    op = model(ip.cuda())\n",
    "    t += ((op.argmax(dim=-1).view(-1,8) == label.cuda()).sum(dim=-1)//8).sum().data\n",
    "    total +=  label.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "34ac800e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7282, device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb400b6",
   "metadata": {},
   "source": [
    "# Seq to Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96c5c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fe0a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(txt,ws=7):\n",
    "    ignore = ws-3\n",
    "    txt = list(txt)\n",
    "    grams = ngrams(txt,ws ,pad_left=True,pad_right=True,left_pad_symbol='L',right_pad_symbol='R')\n",
    "    grams = [list(i)+['R'] for i in grams]\n",
    "    return list(grams)[ignore:-ignore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea4a9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_grams=[]\n",
    "for txt in msa_data:\n",
    "    ng = get_ngrams(txt)\n",
    "    if ng:\n",
    "        msa_grams.extend(ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bda3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(txt):\n",
    "    sz = 2 #int(len(txt)*0.2)\n",
    "    noise_sz = np.random.randint(0,sz if sz>1 else 1,1)\n",
    "    replace_idx = np.random.choice(len(txt),noise_sz,replace=False)\n",
    "    letters_idx = np.random.choice(len(i2l)-3,noise_sz,replace=True)\n",
    "    txt = list(txt)\n",
    "    for rep,let in zip(replace_idx,letters_idx):\n",
    "        txt[rep] = i2l[let]\n",
    "    return ''.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cab6969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class arrDs(Dataset):\n",
    "    def __init__(self,txt_list,l2i):\n",
    "        self.data = txt_list\n",
    "        self.l2i = l2i\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        X = noise(self.data[idx])\n",
    "        Y = self.data[idx]\n",
    "        \n",
    "        X = torch.tensor([self.l2i.get(i,l2i['X']) for i in X])\n",
    "        Y = torch.tensor([self.l2i.get(i,l2i['X']) for i in Y])\n",
    "        #numerilize\n",
    "        return torch.stack([X,Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35d69322",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_msa_grams = msa_grams[:int(len(msa_grams)*0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aced99bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data, val_data = part_msa_grams[:int(0.8*len(part_msa_grams))],part_msa_grams[int(0.8*len(part_msa_grams)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8e43eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds,val_ds = arrDs(trn_data,l2i),arrDs(val_data,l2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "023a3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds,batch_size=256,drop_last=False,shuffle=True)\n",
    "val_dl = DataLoader(val_ds,batch_size=256,drop_last=False,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71915de",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f9b7cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5d20fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AC_ENC(nn.Module):\n",
    "    def __init__(self,num_emb,vs,hs,num_layers=1,dp=0.0,bidirectional=True):\n",
    "        '''Autocorrect encoder\n",
    "        num emb : vocab size\n",
    "        vs: vector size of the embeddings\n",
    "        hs: hidden size of RNNs\n",
    "        num_layers: number of layers\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.hs = hs\n",
    "        self.emb = nn.Embedding(num_emb,vs)\n",
    "        self.enc_gru = nn.GRU(vs,hs,num_layers=num_layers,dropout=dp,\n",
    "                              bidirectional=bidirectional,batch_first=True)\n",
    "    def forward(self,x):\n",
    "        bs,seq_len=x.shape\n",
    "        x = self.emb(x)\n",
    "        x = self.enc_gru(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b6e789e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "313f041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = AC_ENC(36,32,32,bidirectional=False,num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1509aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_op,enc_hidden = enc(a[:,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2b388cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AC_DEC(nn.Module):\n",
    "    def __init__(self,num_emb,vs,hs,num_layers=1,dp=0.0,bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.num_emb = num_emb\n",
    "        self.emb = nn.Embedding(num_emb,vs)\n",
    "        self.dec_gru = nn.GRU(vs,hs,num_layers=num_layers,dropout=dp,\n",
    "                              bidirectional=False,batch_first=True)\n",
    "        self.unifier = nn.Sequential(nn.Linear(num_layers*(2 if bidirectional==True else 1),num_layers),\n",
    "                                nn.ReLU()) \n",
    "        self.lin = nn.Sequential(nn.Linear(hs,num_emb),\n",
    "                                nn.LogSoftmax(dim=-1))\n",
    "    def forward(self,hidden,label=None):\n",
    "        _,bs,hs=hidden.shape\n",
    "        op_list=[]\n",
    "        op_list_prob = []\n",
    "        hidden = self.unifier(hidden.permute(2,1,0)).permute(2,1,0).contiguous()\n",
    "        inp = torch.tensor(l2i['L']).repeat(bs,1).cuda()\n",
    "        for i in range(8):\n",
    "            op = self.emb(inp)\n",
    "            op,hidden = self.dec_gru(op,hidden)\n",
    "            word_prob = self.lin(hidden)\n",
    "            \n",
    "            \n",
    "            if label is not None:\n",
    "                inp = label[:,i].clone()[:,None]\n",
    "            else:\n",
    "                inp = torch.argmax(word_prob,dim=-1)[0].unsqueeze(-1)\n",
    "            hidden = hidden.detach() \n",
    "            op_list_prob.append(word_prob)\n",
    "            op_list.append(inp.detach())\n",
    "        \n",
    "        prob = torch.stack(op_list_prob,dim=1)[-1:].permute(2,0,1,3)#4,15,256,36\n",
    "        seq = torch.stack(op_list).squeeze(-1).T\n",
    "        return prob,seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6c857bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AC_DEC_ATTN(nn.Module):\n",
    "    def __init__(self,num_emb,vs,hs,num_layers=1,dp=0.0,bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.num_emb = num_emb\n",
    "        self.emb = nn.Embedding(num_emb,vs)\n",
    "        self.dec_gru = nn.GRU(vs,hs,num_layers=num_layers,dropout=dp,\n",
    "                              bidirectional=False,batch_first=True)\n",
    "        self.unifier = nn.Sequential(nn.Linear(num_layers*(2 if bidirectional==True else 1),num_layers),\n",
    "                                nn.ReLU()) \n",
    "        self.lin = nn.Sequential(nn.Linear(hs,num_emb),\n",
    "                                nn.LogSoftmax(dim=-1))\n",
    "        \n",
    "        self.attn = nn.Linear(hs * 2, 8)\n",
    "        self.attn_combine = nn.Linear(hs * 2, hs)\n",
    "    def forward(self,hidden,enc_outputs,label=None):\n",
    "        _,bs,hs=hidden.shape\n",
    "        op_list=[]\n",
    "        op_list_prob = []\n",
    "        hidden = self.unifier(hidden.permute(2,1,0)).permute(2,1,0).contiguous()\n",
    "        inp = torch.tensor(l2i['L']).repeat(bs,1).cuda()\n",
    "        for i in range(8):\n",
    "            emb = self.emb(inp)\n",
    "       \n",
    "            op = emb.repeat(1,hidden.size(0),1).permute(1,0,2)\n",
    "            attn = F.softmax(self.attn(torch.cat([op,hidden],dim=-1)),dim=-1).permute(1,0,2)\n",
    "            #print(attn.shape,enc_outputs.shape)\n",
    "            attn_applied = torch.bmm(attn,enc_outputs)\n",
    "            op=F.relu(self.attn_combine(torch.cat([emb,attn_applied],dim=-1)))\n",
    "            #print('attn_applied',op.shape)\n",
    "            op,hidden = self.dec_gru(op,hidden)\n",
    "            #print(op.shape,hidden.shape)\n",
    "            word_prob = self.lin(hidden)\n",
    "            \n",
    "            \n",
    "            if label is not None:\n",
    "                inp = label[:,i].clone()[:,None]\n",
    "            else:\n",
    "                inp = torch.argmax(word_prob,dim=-1)[0].unsqueeze(-1)\n",
    "            hidden = hidden.detach() \n",
    "            op_list_prob.append(word_prob)\n",
    "            op_list.append(inp.detach())\n",
    "        \n",
    "        prob = torch.stack(op_list_prob,dim=1)[-1:].permute(2,0,1,3)#4,15,256,36\n",
    "        seq = torch.stack(op_list).squeeze(-1).T\n",
    "        return prob,seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "99698d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = AC_DEC_ATTN(36,32,32,bidirectional=False,num_layers=1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2fc05189",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = dec(enc_hidden.cuda(),enc_op.cuda(),a[:,1,:].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "45ce444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AC(nn.Module):\n",
    "    def __init__(self,num_emb,vs,hs,num_layers=1,dp=0.0,bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.enc = AC_ENC(num_emb,hs,hs,num_layers=num_layers,dp=dp,bidirectional=bidirectional).cuda()\n",
    "        self.dec = AC_DEC_ATTN(num_emb,hs,hs,num_layers=num_layers,dp=dp,bidirectional=bidirectional).cuda()\n",
    "    def forward(self,x,label=None):\n",
    "        enc_op,enc_hidden = self.enc(x)\n",
    "        dec_prob,dec_seq = self.dec(enc_hidden,enc_op,label)\n",
    "        return dec_prob.contiguous().view(-1,num_emb),dec_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "1ead5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model,trn_dl,val_dl,loss_fnc):\n",
    "    model.train()\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        for batch in tqdm.tqdm(trn_dl,'train'):\n",
    "            opt.zero_grad()\n",
    "            ip,label = batch[:,0,:],batch[:,1,:]\n",
    "            \n",
    "            tgt = label.clone().cuda() if random.random() > 0.5 else None\n",
    "            \n",
    "            op = model(ip.cuda(),tgt)[0]\n",
    "            trn_l = loss_fnc(op,label.contiguous().view(-1).cuda())\n",
    "            trn_l.backward()\n",
    "            opt.step()\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in tqdm.tqdm(val_dl,'validation'):\n",
    "                ip,label = batch[:,0,:],batch[:,1,:]\n",
    "                op = model(ip.cuda())[0]\n",
    "                val_loss = loss_fnc(op,label.contiguous().view(-1).cuda())\n",
    "        print(f'epoch {i+1} train_loss ->',trn_l.item() , 'val_loss ->',val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ca13cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_emb = len(i2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "c0a38049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AC(num_emb,10,512,bidirectional=False,num_layers=1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "bbfa8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "0a82c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(ignore_index=l2i['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "2dbb3907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 145/145 [00:04<00:00, 31.87it/s]\n",
      "validation: 100%|██████████| 37/37 [00:00<00:00, 41.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train_loss -> 1.4358280897140503 val_loss -> 1.7291322946548462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 145/145 [00:04<00:00, 32.66it/s]\n",
      "validation: 100%|██████████| 37/37 [00:00<00:00, 41.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 train_loss -> 0.8792869448661804 val_loss -> 0.5220316052436829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 145/145 [00:04<00:00, 32.20it/s]\n",
      "validation: 100%|██████████| 37/37 [00:00<00:00, 40.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 train_loss -> 0.7479058504104614 val_loss -> 0.7096359133720398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 145/145 [00:04<00:00, 32.44it/s]\n",
      "validation: 100%|██████████| 37/37 [00:00<00:00, 40.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 train_loss -> 0.3371341824531555 val_loss -> 0.24764351546764374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 145/145 [00:04<00:00, 32.34it/s]\n",
      "validation: 100%|██████████| 37/37 [00:00<00:00, 40.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 train_loss -> 0.6555259227752686 val_loss -> 1.0536491870880127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(5,model,trn_dl,val_dl,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "42dbe636",
   "metadata": {},
   "outputs": [],
   "source": [
    "b= iter(val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "95f79e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "02dc30f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = a[:,1,:].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "0b0c5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = model(a[:,0,:].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "0bd97675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 8])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "235054e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for i,tensor in enumerate(op[1]):\n",
    "    if (tensor==tgt[i]).sum()/len(tensor) == 1:\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "2f277bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "fde17eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 18,  7, 29, 27,  0, 28, 33], device='cuda:0')"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f9d8cf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18, 18,  7, 29, 27,  0, 28, 33],\n",
       "        [18,  0,  7, 29, 27,  0, 28, 33]])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "240a1968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18,  0,  7, 29, 27,  0, 28, 33], device='cuda:0')"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064876ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
