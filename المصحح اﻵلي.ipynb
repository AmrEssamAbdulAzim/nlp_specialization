{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c26980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amr/anaconda3/envs/torch/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "import collections\n",
    "import pyarabic.araby as araby\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9c23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd66ddec",
   "metadata": {},
   "source": [
    "# Data\n",
    "### Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2830b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(t):\n",
    "    t = araby.strip_tashkeel(t)\n",
    "    t = araby.normalize_hamza(t)\n",
    "    t = araby.normalize_alef(t)\n",
    "    t = araby.strip_tatweel(t)\n",
    "    t = araby.normalize_teh(t)\n",
    "    t = re.sub(\"ى\",\"ي\",t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4648ab6",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1bff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= np.load('../translation project/AD_NMT-master/LAV-MSA-2-both.pkl',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40c6c699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['لا انا بعرف وحدة راحت ع فرنسا و معا شنتا حطت فيها الفرش',\n",
       " 'لا اعرف واحدة ذهبت الى فرنسا و لها غرفة و ضعت فيها الافرشة']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0] # lav , msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2325e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only msa text\n",
    "msa=[]\n",
    "for i,ex in enumerate(data):\n",
    "    msa_text = normalization(ex[1])\n",
    "    data[i][1] = msa_text\n",
    "    msa.append(msa_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a93c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = ' '.join(msa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb9b2e",
   "metadata": {},
   "source": [
    "Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f0b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_d=collections.Counter(msa.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cd9b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef7c5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2msa = np.array([word for word,freq in msa_d.items() if freq > min_count ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28f48369",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa2idx = {word:i for i,word in enumerate(idx2msa)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e7b71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_data = [' '.join([i for i in t[1].split() if (msa2idx.get(i,-1) != -1 and t[1] != '')]) for t in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fa4acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_data = [i for i in msa_data if i != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e82986f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(i) for i in msa.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40a4668f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.8950e+03, 1.9324e+04, 0.0000e+00, 2.4495e+04, 0.0000e+00,\n",
       "        2.6011e+04, 2.0113e+04, 0.0000e+00, 1.1975e+04, 0.0000e+00,\n",
       "        6.5210e+03, 1.9170e+03, 0.0000e+00, 4.9600e+02, 0.0000e+00,\n",
       "        2.2600e+02, 6.2000e+01, 0.0000e+00, 1.1000e+01, 5.0000e+00]),\n",
       " array([ 1. ,  1.6,  2.2,  2.8,  3.4,  4. ,  4.6,  5.2,  5.8,  6.4,  7. ,\n",
       "         7.6,  8.2,  8.8,  9.4, 10. , 10.6, 11.2, 11.8, 12.4, 13. ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lengths,bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cfdecf",
   "metadata": {},
   "source": [
    "Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1029c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = gensim.models.Word2Vec.load('../resources/models/word vectors/word2vec/wiki/full_grams_cbow_100_wiki/full_grams_cbow_100_wiki.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28d6d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2l = list(set(normalization(araby.LETTERS)))\n",
    "i2v = {}\n",
    "for index,letter in enumerate(i2l):\n",
    "    if letter in t_model.wv.index_to_key :\n",
    "        i2v[index] = t_model.wv.get_vector(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc4777a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2v.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c0694af",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2l.append(' ')#Space\n",
    "i2l.append('s')#eos\n",
    "i2l.append('E')#Empty\n",
    "i2l.append('X')#UNK\n",
    "i2l.append('P')#pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef9d2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2i = {v:i for i,v in enumerate(i2l)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91a846c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(i2l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904d2f5",
   "metadata": {},
   "source": [
    "ALL in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e861bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a013086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a37ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(txt):\n",
    "    sz = int(len(txt)*0.2)\n",
    "    noise_sz = np.random.randint(0,sz if sz>1 else 1,1)\n",
    "    replace_idx = np.random.choice(len(txt),noise_sz,replace=False)\n",
    "    letters_idx = np.random.choice(len(i2l)-3,noise_sz,replace=True)\n",
    "    txt = list(txt)\n",
    "    for rep,let in zip(replace_idx,letters_idx):\n",
    "        txt[rep] = i2l[let]\n",
    "    return ''.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e87cbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class arrDs(Dataset):\n",
    "    def __init__(self,txt_list,l2i):\n",
    "        self.data = txt_list\n",
    "        self.l2i = l2i\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        X = noise(self.data[idx])\n",
    "        Y = self.data[idx]\n",
    "        \n",
    "        X = torch.tensor([self.l2i.get(i,31) for i in X])\n",
    "        Y = torch.tensor([self.l2i.get(i,31) for i in Y])\n",
    "        #numerilize\n",
    "        return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "63302423",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data, val_data = msa_data[:int(0.8*len(msa_data))],msa_data[int(0.8*len(msa_data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "436a140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds,val_ds = arrDs(trn_data,l2i),arrDs(val_data,l2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e0d2e260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12, 21, 29, 21, 15,  2,  5, 29, 28, 21, 20, 11,  8, 29, 13,  8, 18,  7,\n",
       "         29, 21, 12, 21, 29,  5,  2, 18, 24, 21, 29, 28, 29, 12,  8, 21, 29,  9,\n",
       "          2,  5,  8, 29, 28, 29,  5, 27,  8, 21, 30, 21, 13,  8, 18]),\n",
       " tensor([18]))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4dda7660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    label  = [i for _,i in data]\n",
    "    label = pad_sequence(label,batch_first=True,padding_value=32)\n",
    "    data = [i for i,_ in data]\n",
    "    data = pad_sequence(data,batch_first=True,padding_value=32)\n",
    "    return label,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "09f0bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds,batch_size=32,collate_fn=collate_fn,drop_last=False)\n",
    "val_dl = DataLoader(val_ds,batch_size=32,collate_fn=collate_fn,drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0abb8f5",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d34c2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c6906af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autocorrect(nn.Module):\n",
    "    def __init__(self,num_emb,vs,hs,bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_emb,vs)\n",
    "        self.gru = nn.GRU(vs,hs,num_layers=3,bidirectional=bidirectional,batch_first=True,dropout=0.2)\n",
    "        self.lin = nn.Sequential(nn.Linear(2*hs if bidirectional == True else hs,hs),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(hs,num_emb))\n",
    "    def forward(self,x):\n",
    "        bs,seq_len=x.shape\n",
    "        x = self.emb(x)\n",
    "        x,_ = self.gru(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.lin(x)\n",
    "        return torch.softmax(x,dim=-1).view(bs*seq_len,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "af211677",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_emb = len(i2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d189c309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = autocorrect(num_emb,100,512).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "d685d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load available vectors\n",
    "model.emb.weight.requires_grad_(False)\n",
    "for i in i2v.keys():\n",
    "    model.emb.weight[i] = nn.Parameter(torch.from_numpy(i2v[i].copy())).requires_grad_(False)\n",
    "model.emb.weight.requires_grad_(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "bd5d1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "7b05d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(ignore_index=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "1eaa06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model,val_dl,trn_dl,loss_fnc):\n",
    "    model.train()\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        for batch in trn_dl:\n",
    "            opt.zero_grad()\n",
    "            ip,label = batch\n",
    "            op = model(ip.cuda())\n",
    "            trn_l = loss_fnc(op,label.view(-1).cuda())\n",
    "            trn_l.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in val_dl:\n",
    "                ip,label = batch\n",
    "                op = model(ip.cuda())\n",
    "                val_loss = loss_fnc(op,label.view(-1).cuda())\n",
    "        print('train_loss ->',trn_l.item() , 'val_loss ->',val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b06cff7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.825662136077881 val_loss -> 2.883354663848877\n",
      "train_loss -> 3.1756622791290283 val_loss -> 3.191047191619873\n",
      "train_loss -> 2.775662899017334 val_loss -> 3.1141245365142822\n",
      "train_loss -> 3.025662899017334 val_loss -> 3.037201166152954\n"
     ]
    }
   ],
   "source": [
    "train(4,model,trn_dl,val_dl,loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca7ff86",
   "metadata": {},
   "source": [
    "## N-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b049d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1365938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(txt,ws=11):\n",
    "    ignore = ws //2\n",
    "    txt = list(txt)\n",
    "    grams = ngrams(txt,ws ,pad_left=True,pad_right=True,left_pad_symbol='P',right_pad_symbol='P')\n",
    "    return list(grams)[ignore:-ignore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8225f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_grams=[]\n",
    "for txt in msa_data:\n",
    "    msa_grams.extend(get_ngrams(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a9feb590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6457555610677899"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "da7c66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(txt):\n",
    "    replace_idx = len(txt)//2\n",
    "    letter = txt[replace_idx]\n",
    "    txt=list(txt)\n",
    "    del txt[replace_idx]\n",
    "    \n",
    "    return ''.join(txt),letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "261d0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class arrDs(Dataset):\n",
    "    def __init__(self,txt_list,l2i):\n",
    "        self.data = txt_list\n",
    "        self.l2i = l2i\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        X,Y = noise(self.data[idx])\n",
    "        #numerilize\n",
    "        X = torch.tensor([self.l2i.get(i,self.l2i['X']) for i in X])\n",
    "        Y = torch.tensor([self.l2i.get(i,self.l2i['X']) for i in [Y]])\n",
    "        \n",
    "        return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0ac95e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data, val_data = msa_grams[:int(0.8*len(msa_grams))],msa_grams[int(0.8*len(msa_grams)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "17c0fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds,val_ds = arrDs(trn_data,l2i),arrDs(val_data,l2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "437edf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    label  = [i for _,i in data]\n",
    "    #label = pad_sequence(label,batch_first=True,padding_value=32)\n",
    "    data = [i for i,_ in data]\n",
    "    data = pad_sequence(data,batch_first=True,padding_value=33)\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f897712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds,batch_size=32,collate_fn=collate_fn,drop_last=False)\n",
    "val_dl = DataLoader(val_ds,batch_size=32,collate_fn=collate_fn,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "93c94d50",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[12, 21, 29,  ..., 13,  8, 18],\n",
       "         [21, 29, 21,  ...,  8, 18, 29],\n",
       "         [29, 21, 15,  ..., 18, 29,  7],\n",
       "         ...,\n",
       "         [28, 29, 12,  ..., 29, 27, 17],\n",
       "         [29, 12,  8,  ..., 27, 17, 28],\n",
       "         [12,  8, 21,  ..., 17, 28, 25]]),\n",
       " [tensor([5]),\n",
       "  tensor([7]),\n",
       "  tensor([14]),\n",
       "  tensor([7]),\n",
       "  tensor([3]),\n",
       "  tensor([1]),\n",
       "  tensor([2]),\n",
       "  tensor([11]),\n",
       "  tensor([22]),\n",
       "  tensor([3]),\n",
       "  tensor([15]),\n",
       "  tensor([14]),\n",
       "  tensor([12]),\n",
       "  tensor([14]),\n",
       "  tensor([25]),\n",
       "  tensor([2]),\n",
       "  tensor([13]),\n",
       "  tensor([27]),\n",
       "  tensor([16]),\n",
       "  tensor([25]),\n",
       "  tensor([24]),\n",
       "  tensor([16]),\n",
       "  tensor([29]),\n",
       "  tensor([7]),\n",
       "  tensor([28]),\n",
       "  tensor([21]),\n",
       "  tensor([5]),\n",
       "  tensor([19]),\n",
       "  tensor([6]),\n",
       "  tensor([10]),\n",
       "  tensor([17]),\n",
       "  tensor([28])])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(trn_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e11d16",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c7970653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "23d3d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autocorrect(nn.Module):\n",
    "    def __init__(self,num_emb,vs,hs,bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_emb,vs)\n",
    "        self.enc_gru = nn.GRU(vs,hs,num_layers=1,bidirectional=False,batch_first=True,dropout=0.2)\n",
    "        self.dec_gru = nn.GRU(vs,hs,num_layers=1,bidirectional=False,batch_first=True,dropout=0.2)\n",
    "        self.lin = nn.Linear(hs,num_emb)\n",
    "    def forward(self,x):\n",
    "        \n",
    "        bs,seq_len=x.shape\n",
    "        print(bs)\n",
    "        x = self.emb(x)\n",
    "        _,x = self.gru(x)\n",
    "        x = x.permute(1,0,2)\n",
    "        x=x.reshape(32,-1)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.lin(x)\n",
    "        return torch.softmax(x,dim=-1).view(bs*seq_len,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f5fcf1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_emb = len(i2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "125dd843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = autocorrect(num_emb,100,512).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "72bfe6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load available vectors\n",
    "model.emb.weight.requires_grad_(False)\n",
    "for i in i2v.keys():\n",
    "    model.emb.weight[i] = nn.Parameter(torch.from_numpy(i2v[i].copy())).requires_grad_(False)\n",
    "model.emb.weight.requires_grad_(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2982db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ae6875e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(ignore_index=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "51d6170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model,val_dl,trn_dl,loss_fnc):\n",
    "    model.train()\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        for batch in trn_dl:\n",
    "            opt.zero_grad()\n",
    "            ip,label = batch\n",
    "            op = model(ip.cuda())\n",
    "            trn_l = loss_fnc(op,label.view(-1).cuda())\n",
    "            trn_l.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in val_dl:\n",
    "                ip,label = batch\n",
    "                op = model(ip.cuda())\n",
    "                val_loss = loss_fnc(op,label.view(-1).cuda())\n",
    "        print('train_loss ->',trn_l.item() , 'val_loss ->',val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "06e9d8b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.966956377029419 val_loss -> 2.9245524406433105\n",
      "train_loss -> 2.8179426193237305 val_loss -> 2.78366756439209\n",
      "train_loss -> 2.713853597640991 val_loss -> 2.6620876789093018\n",
      "train_loss -> 2.671865463256836 val_loss -> 2.632185459136963\n",
      "train_loss -> 2.6573901176452637 val_loss -> 2.611616373062134\n",
      "train_loss -> 2.6203505992889404 val_loss -> 2.578900098800659\n",
      "train_loss -> 2.6199350357055664 val_loss -> 2.5786995887756348\n",
      "train_loss -> 2.612917900085449 val_loss -> 2.5740554332733154\n",
      "train_loss -> 2.6128077507019043 val_loss -> 2.5739822387695312\n",
      "train_loss -> 2.6127774715423584 val_loss -> 2.5739588737487793\n",
      "train_loss -> 2.563910722732544 val_loss -> 2.573953866958618\n",
      "train_loss -> 2.5590922832489014 val_loss -> 2.5646677017211914\n",
      "train_loss -> 2.559047222137451 val_loss -> 2.5551881790161133\n",
      "train_loss -> 2.558993101119995 val_loss -> 2.5551440715789795\n",
      "train_loss -> 2.556666374206543 val_loss -> 2.5520050525665283\n",
      "train_loss -> 2.5519909858703613 val_loss -> 2.548866033554077\n",
      "train_loss -> 2.551971912384033 val_loss -> 2.5488531589508057\n",
      "train_loss -> 2.5519611835479736 val_loss -> 2.5488479137420654\n",
      "train_loss -> 2.5519556999206543 val_loss -> 2.548844814300537\n",
      "train_loss -> 2.551952600479126 val_loss -> 2.5488433837890625\n",
      "train_loss -> 2.5519490242004395 val_loss -> 2.5488414764404297\n",
      "train_loss -> 2.5507471561431885 val_loss -> 2.5488736629486084\n",
      "train_loss -> 2.5472893714904785 val_loss -> 2.5488500595092773\n",
      "train_loss -> 2.54728364944458 val_loss -> 2.5488438606262207\n",
      "train_loss -> 2.547276735305786 val_loss -> 2.548841953277588\n",
      "train_loss -> 2.547274589538574 val_loss -> 2.548840045928955\n",
      "train_loss -> 2.5472733974456787 val_loss -> 2.5488390922546387\n",
      "train_loss -> 2.5472729206085205 val_loss -> 2.5488381385803223\n",
      "train_loss -> 2.547272205352783 val_loss -> 2.548837423324585\n",
      "train_loss -> 2.547283411026001 val_loss -> 2.5488462448120117\n",
      "train_loss -> 2.547274112701416 val_loss -> 2.5488383769989014\n",
      "train_loss -> 2.547272205352783 val_loss -> 2.548837184906006\n",
      "train_loss -> 2.5480051040649414 val_loss -> 2.54777455329895\n",
      "train_loss -> 2.5472755432128906 val_loss -> 2.5472755432128906\n",
      "train_loss -> 2.5472726821899414 val_loss -> 2.5472726821899414\n",
      "train_loss -> 2.547271728515625 val_loss -> 2.5472710132598877\n",
      "train_loss -> 2.5472707748413086 val_loss -> 2.5472702980041504\n",
      "train_loss -> 2.547269105911255 val_loss -> 2.547269582748413\n",
      "train_loss -> 2.547269105911255 val_loss -> 2.547269344329834\n",
      "train_loss -> 2.547268867492676 val_loss -> 2.547269344329834\n",
      "train_loss -> 2.5472686290740967 val_loss -> 2.5472686290740967\n",
      "train_loss -> 2.5472686290740967 val_loss -> 2.5472683906555176\n",
      "train_loss -> 2.5472686290740967 val_loss -> 2.5472683906555176\n",
      "train_loss -> 2.5472679138183594 val_loss -> 2.5472683906555176\n",
      "train_loss -> 2.5472681522369385 val_loss -> 2.5472681522369385\n",
      "train_loss -> 2.5472679138183594 val_loss -> 2.5472679138183594\n",
      "train_loss -> 2.5472676753997803 val_loss -> 2.5472679138183594\n",
      "train_loss -> 2.5472676753997803 val_loss -> 2.5472679138183594\n",
      "train_loss -> 2.5472676753997803 val_loss -> 2.5472676753997803\n",
      "train_loss -> 2.5472676753997803 val_loss -> 2.5472676753997803\n"
     ]
    }
   ],
   "source": [
    "train(50,model,trn_dl,val_dl,loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae20d15",
   "metadata": {},
   "source": [
    "# Seq to Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8e04963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92a19909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c6b50e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68186343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(txt,ws=5):\n",
    "    ignore = ws-2\n",
    "    txt = list(txt)\n",
    "    grams = ngrams(txt,ws ,pad_left=True,pad_right=True,left_pad_symbol='Q',right_pad_symbol='W')\n",
    "    return list(grams)[ignore:-ignore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2db9fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data = ['ق' * 10]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70844b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_grams=[]\n",
    "for txt in fake_data:\n",
    "    ng = get_ngrams(txt)\n",
    "    if ng:\n",
    "        msa_grams.extend(ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69c54bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(txt):\n",
    "    sz = int(len(txt)*0.2)\n",
    "    noise_sz = np.random.randint(0,sz if sz>1 else 1,1)\n",
    "    replace_idx = np.random.choice(len(txt),noise_sz,replace=False)\n",
    "    letters_idx = np.random.choice(len(i2l)-3,noise_sz,replace=True)\n",
    "    txt = list(txt)\n",
    "    for rep,let in zip(replace_idx,letters_idx):\n",
    "        txt[rep] = i2l[let]\n",
    "    return ''.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb799d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class arrDs(Dataset):\n",
    "    def __init__(self,txt_list,l2i):\n",
    "        self.data = txt_list\n",
    "        self.l2i = l2i\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        #X = noise(self.data[idx])\n",
    "        X = self.data[idx]\n",
    "        Y = self.data[idx]\n",
    "        \n",
    "        X = torch.tensor([self.l2i.get(i,31) for i in X])\n",
    "        Y = torch.tensor([self.l2i.get(i,31) for i in Y])\n",
    "        #numerilize\n",
    "        return torch.stack([X,Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14ba0638",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data, val_data = msa_grams[:int(0.8*len(msa_grams))],msa_grams[int(0.8*len(msa_grams)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "928866d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds,val_ds = arrDs(trn_data,l2i),arrDs(val_data,l2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b9a926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = trn_ds[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ff4d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds,batch_size=4,drop_last=False)\n",
    "val_dl = DataLoader(val_ds,batch_size=4,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "848d1cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip,label = next(iter(trn_dl))[:,0,:],next(iter(trn_dl))[:,1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70a3246",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd272f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6165f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autocorrect(nn.Module):\n",
    "    def __init__(self,num_emb,vs,hs,bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.hs = hs\n",
    "        self.emb = nn.Embedding(num_emb,vs)\n",
    "        self.enc_gru = nn.GRU(vs,hs,num_layers=1,bidirectional=False,batch_first=True)\n",
    "        self.dec_gru = nn.GRU(hs,hs,num_layers=1,bidirectional=False,batch_first=True)\n",
    "        self.lin = nn.Sequential(nn.Linear(hs,hs),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(hs,num_emb))\n",
    "    def forward(self,x):\n",
    "        bs,seq_len=x.shape\n",
    "        x = self.emb(x)\n",
    "        #print('emb',x.shape)\n",
    "        x = self.enc_gru(x)\n",
    "        #print('enc',x[0].shape)\n",
    "        op=[]\n",
    "        sos = torch.zeros(bs,1,self.hs).cuda()\n",
    "        h = x[1]\n",
    "        for i in range(5):\n",
    "            sos,h = model.dec_gru(sos,h)\n",
    "            op.append(h)\n",
    "        #    print('h',h.shape)\n",
    "        x = torch.stack(op,dim=1).squeeze().permute(1,0,2)\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        #print('lin',x.shape)\n",
    "        return torch.softmax(x,dim=-1).permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "46ef0418",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_emb = len(i2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "70ff98ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = autocorrect(num_emb,5,6).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f6c9d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load available vectors\n",
    "#model.emb.weight.requires_grad_(False)\n",
    "#for i in i2v.keys():\n",
    "#    model.emb.weight[i] = nn.Parameter(torch.from_numpy(i2v[i].copy())).requires_grad_(False)\n",
    "#model.emb.weight.requires_grad_(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "31089929",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3fedcf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(ignore_index=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "05a27a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model,val_dl,trn_dl,loss_fnc):\n",
    "    model.train()\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        for batch in tqdm.tqdm(trn_dl,'train'):\n",
    "            opt.zero_grad()\n",
    "            ip,label = batch[:,0,:],batch[:,1,:]\n",
    "            op = model(ip.cuda())\n",
    "            trn_l = loss_fnc(op,label.cuda())\n",
    "            trn_l.backward()\n",
    "            opt.step()\n",
    "            print(trn_l)\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in tqdm.tqdm(val_dl,'validation'):\n",
    "                ip,label = batch[:,0,:],batch[:,1,:]\n",
    "                op = model(ip.cuda())\n",
    "                val_loss = loss_fnc(op,label.cuda())\n",
    "        print('train_loss ->',trn_l.item() , 'val_loss ->',val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "649250a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "366c2fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  12%|█▏        | 49/400 [00:00<00:01, 245.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5356, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(3.0183, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  25%|██▌       | 100/400 [00:00<00:01, 248.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  38%|███▊      | 151/400 [00:00<00:01, 248.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  51%|█████     | 203/400 [00:00<00:00, 252.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  64%|██████▍   | 255/400 [00:01<00:00, 253.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "train:  70%|███████   | 281/400 [00:01<00:00, 252.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  83%|████████▎ | 332/400 [00:01<00:00, 249.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 400/400 [00:01<00:00, 250.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|██████████| 1600/1600 [00:01<00:00, 1050.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.6256630420684814 val_loss -> 2.6256630420684814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   6%|▌         | 24/400 [00:00<00:01, 239.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "train:  12%|█▏        | 49/400 [00:00<00:01, 244.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "train:  18%|█▊        | 74/400 [00:00<00:01, 242.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "train:  25%|██▌       | 100/400 [00:00<00:01, 247.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "train:  31%|███▏      | 125/400 [00:00<00:01, 244.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  44%|████▎     | 174/400 [00:00<00:00, 234.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  56%|█████▌    | 224/400 [00:00<00:00, 238.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  68%|██████▊   | 274/400 [00:01<00:00, 242.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  81%|████████  | 324/400 [00:01<00:00, 242.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  94%|█████████▎| 374/400 [00:01<00:00, 246.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 400/400 [00:01<00:00, 242.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.6257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|██████████| 1600/1600 [00:01<00:00, 1068.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.6256630420684814 val_loss -> 2.6256630420684814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(2,model,trn_dl,val_dl,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a15d7695",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = next(iter(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eedac3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 5])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4407aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 5])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "984dbd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb torch.Size([4, 5, 5])\n",
      "enc torch.Size([4, 5, 6])\n",
      "h torch.Size([1, 4, 6])\n",
      "h torch.Size([1, 4, 6])\n",
      "h torch.Size([1, 4, 6])\n",
      "h torch.Size([1, 4, 6])\n",
      "h torch.Size([1, 4, 6])\n",
      "lin torch.Size([4, 5, 34])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randint(0,34,(4,5)).cuda()).argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d46f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a039f6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6614)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.cross_entropy(torch.rand(10,5,10),torch.randint(0,5,(10,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "b6ffd1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "37ca60c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "?tqdm.tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "1fd1537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 137970.53it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(10)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "99a4c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "53b286ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3026)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(torch.ones(5,10),torch.ones(5).type(torch.LongTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d999a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
