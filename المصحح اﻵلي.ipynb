{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c26980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amr/anaconda3/envs/torch/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "import collections\n",
    "import pyarabic.araby as araby\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c9c23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd66ddec",
   "metadata": {},
   "source": [
    "# Data\n",
    "### Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2830b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(t):\n",
    "    t = araby.strip_tashkeel(t)\n",
    "    t = araby.normalize_hamza(t)\n",
    "    t = araby.normalize_alef(t)\n",
    "    t = araby.strip_tatweel(t)\n",
    "    t = araby.normalize_teh(t)\n",
    "    t = re.sub(\"ى\",\"ي\",t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4648ab6",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad1bff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= np.load('../translation project/AD_NMT-master/LAV-MSA-2-both.pkl',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40c6c699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['لا انا بعرف وحدة راحت ع فرنسا و معا شنتا حطت فيها الفرش',\n",
       " 'لا اعرف واحدة ذهبت الى فرنسا و لها غرفة و ضعت فيها الافرشة']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0] # lav , msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2325e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only msa text\n",
    "msa=[]\n",
    "for i,ex in enumerate(data):\n",
    "    msa_text = normalization(ex[1])\n",
    "    data[i][1] = msa_text\n",
    "    msa.append(msa_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a93c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = ' '.join(msa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb9b2e",
   "metadata": {},
   "source": [
    "Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85f0b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_d=collections.Counter(msa.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cd9b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef7c5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2msa = np.array([word for word,freq in msa_d.items() if freq > min_count ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28f48369",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa2idx = {word:i for i,word in enumerate(idx2msa)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e7b71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_data = [' '.join([i for i in t[1].split() if (msa2idx.get(i,-1) != -1 and t[1] != '')]) for t in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fa4acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_data = [i for i in msa_data if i != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e82986f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(i) for i in msa.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40a4668f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.8950e+03, 1.9324e+04, 0.0000e+00, 2.4495e+04, 0.0000e+00,\n",
       "        2.6011e+04, 2.0113e+04, 0.0000e+00, 1.1975e+04, 0.0000e+00,\n",
       "        6.5210e+03, 1.9170e+03, 0.0000e+00, 4.9600e+02, 0.0000e+00,\n",
       "        2.2600e+02, 6.2000e+01, 0.0000e+00, 1.1000e+01, 5.0000e+00]),\n",
       " array([ 1. ,  1.6,  2.2,  2.8,  3.4,  4. ,  4.6,  5.2,  5.8,  6.4,  7. ,\n",
       "         7.6,  8.2,  8.8,  9.4, 10. , 10.6, 11.2, 11.8, 12.4, 13. ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lengths,bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cfdecf",
   "metadata": {},
   "source": [
    "Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1029c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = gensim.models.Word2Vec.load('../resources/models/word vectors/word2vec/wiki/full_grams_cbow_100_wiki/full_grams_cbow_100_wiki.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28d6d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2l = list(set(normalization(araby.LETTERS)))\n",
    "i2v = {}\n",
    "for index,letter in enumerate(i2l):\n",
    "    if letter in t_model.wv.index_to_key :\n",
    "        i2v[index] = t_model.wv.get_vector(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc4777a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2v.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c0694af",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2l.append(' ')#Space\n",
    "i2l.append('s')#eos\n",
    "i2l.append('E')#Empty\n",
    "i2l.append('X')#UNK\n",
    "i2l.append('P')#pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef9d2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2i = {v:i for i,v in enumerate(i2l)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91a846c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(i2l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904d2f5",
   "metadata": {},
   "source": [
    "## ALL in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e861bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a013086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8a37ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(txt):\n",
    "    sz = 2#int(len(txt)*0.2)\n",
    "    noise_sz = np.random.randint(0,sz if sz>1 else 1,1)\n",
    "    replace_idx = np.random.choice(len(txt),noise_sz,replace=False)\n",
    "    letters_idx = np.random.choice(len(i2l)-3,noise_sz,replace=True)\n",
    "    txt = list(txt)\n",
    "    for rep,let in zip(replace_idx,letters_idx):\n",
    "        txt[rep] = i2l[let]\n",
    "    return ''.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e87cbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class arrDs(Dataset):\n",
    "    def __init__(self,txt_list,l2i):\n",
    "        self.data = txt_list\n",
    "        self.l2i = l2i\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        X = noise(self.data[idx])\n",
    "        Y = self.data[idx]\n",
    "        \n",
    "        X = torch.tensor([self.l2i.get(i,31) for i in X])\n",
    "        Y = torch.tensor([self.l2i.get(i,31) for i in Y])\n",
    "        #numerilize\n",
    "        return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "63302423",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data, val_data = msa_grams[:int(0.8*len(msa_grams))],msa_grams[int(0.8*len(msa_grams)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "436a140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds,val_ds = arrDs(trn_data,l2i),arrDs(val_data,l2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4dda7660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    label  = [i for _,i in data]\n",
    "    label = pad_sequence(label,batch_first=True,padding_value=l2i['P'])\n",
    "    data = [i for i,_ in data]\n",
    "    data = pad_sequence(data,batch_first=True,padding_value=l2i['P'])\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "09f0bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds,batch_size=512,collate_fn=collate_fn,drop_last=False,shuffle=True)\n",
    "val_dl = DataLoader(val_ds,batch_size=512,collate_fn=collate_fn,drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0abb8f5",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d34c2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c6906af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autocorrect(nn.Module):\n",
    "    def __init__(self,num_emb,vs,hs,bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_emb,vs)\n",
    "        self.gru = nn.GRU(vs,hs,num_layers=3,bidirectional=bidirectional,batch_first=True,dropout=0.2)\n",
    "        self.lin = nn.Sequential(nn.Linear(2*hs if bidirectional == True else hs,hs),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(hs,num_emb))\n",
    "    def forward(self,x):\n",
    "        bs,seq_len=x.shape\n",
    "        x = torch.relu(self.emb(x))\n",
    "        x,_ = self.gru(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.lin(x)\n",
    "        return torch.log_softmax(x,dim=-1).view(bs*seq_len,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "af211677",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_emb = len(i2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d189c309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = autocorrect(num_emb,100,512).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d685d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load available vectors\n",
    "model.emb.weight.requires_grad_(False)\n",
    "for i in i2v.keys():\n",
    "    model.emb.weight[i] = nn.Parameter(torch.from_numpy(i2v[i].copy())).requires_grad_(False)\n",
    "model.emb.weight.requires_grad_(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bd5d1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7b05d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(ignore_index=l2i['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1eaa06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model,trn_dl,val_dl,loss_fnc):\n",
    "    model.train()\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        for batch in tqdm(trn_dl,desc='train'):\n",
    "            opt.zero_grad()\n",
    "            ip,label = batch\n",
    "            op = model(ip.cuda())\n",
    "            trn_l = loss_fnc(op,label.view(-1).cuda())\n",
    "            trn_l.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in tqdm(val_dl,desc='validation'):\n",
    "                ip,label = batch\n",
    "                op = model(ip.cuda())\n",
    "                val_loss = loss_fnc(op,label.view(-1).cuda())\n",
    "        print('train_loss ->',trn_l.item() , 'val_loss ->',val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b06cff7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 770/770 [01:40<00:00,  7.67it/s]\n",
      "validation: 100%|██████████| 193/193 [00:11<00:00, 16.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 0.15521708130836487 val_loss -> 0.17286837100982666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 770/770 [01:40<00:00,  7.66it/s]\n",
      "validation: 100%|██████████| 193/193 [00:11<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 0.10659952461719513 val_loss -> 0.13384029269218445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 770/770 [01:40<00:00,  7.64it/s]\n",
      "validation: 100%|██████████| 193/193 [00:11<00:00, 16.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 0.13054075837135315 val_loss -> 0.12543432414531708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 770/770 [01:40<00:00,  7.68it/s]\n",
      "validation: 100%|██████████| 193/193 [00:11<00:00, 16.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 0.13228930532932281 val_loss -> 0.10668586194515228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(4,model,trn_dl,val_dl,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0ac4e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0da8ead8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22,  6, 12,  ..., 21, 16, 29],\n",
       "        [ 6, 12, 29,  ..., 16, 29, 20],\n",
       "        [12, 29, 21,  ..., 29, 20, 13],\n",
       "        ...,\n",
       "        [13, 29, 21,  ..., 33, 33, 33],\n",
       "        [29, 21, 15,  ..., 17, 33, 33],\n",
       "        [21, 15, 11,  ..., 33, 33, 33]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "058570a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(a[0].cuda()).argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6e7f29e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 11])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4e36c1dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-4f5b0490e365>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(res.view(512,-1).cpu()):\n",
    "    if t == a[1][i]:\n",
    "        print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fd34dfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8961)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[1].view(-1)==res.cpu()).sum() / len(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca7ff86",
   "metadata": {},
   "source": [
    "## N-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b049d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f1365938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(txt,ws=11):\n",
    "    ignore = ws //2\n",
    "    txt = list(txt)\n",
    "    grams = ngrams(txt,ws ,pad_left=True,pad_right=True,left_pad_symbol='P',right_pad_symbol='P')\n",
    "    return list(grams)[ignore:-ignore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8225f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_grams=[]\n",
    "for txt in msa_data:\n",
    "    msa_grams.extend(get_ngrams(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a9feb590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4198946819035053"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da7c66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(txt):\n",
    "    replace_idx = len(txt)//2\n",
    "    letter = txt[replace_idx]\n",
    "    txt=list(txt)\n",
    "    del txt[replace_idx]\n",
    "    \n",
    "    return ''.join(txt),letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "261d0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class arrDs(Dataset):\n",
    "    def __init__(self,txt_list,l2i):\n",
    "        self.data = txt_list\n",
    "        self.l2i = l2i\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        X,Y = noise(self.data[idx])\n",
    "        #numerilize\n",
    "        X = torch.tensor([self.l2i.get(i,self.l2i['X']) for i in X])\n",
    "        Y = torch.tensor([self.l2i.get(i,self.l2i['X']) for i in [Y]])\n",
    "        \n",
    "        return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0ac95e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data, val_data = msa_grams[:int(0.8*len(msa_grams))],msa_grams[int(0.8*len(msa_grams)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "17c0fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds,val_ds = arrDs(trn_data,l2i),arrDs(val_data,l2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "437edf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    label  = [i for _,i in data]\n",
    "    #label = pad_sequence(label,batch_first=True,padding_value=32)\n",
    "    data = [i for i,_ in data]\n",
    "    data = pad_sequence(data,batch_first=True,padding_value=33)\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f897712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds,batch_size=32,collate_fn=collate_fn,drop_last=False)\n",
    "val_dl = DataLoader(val_ds,batch_size=32,collate_fn=collate_fn,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "93c94d50",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[12, 21, 29,  ..., 13,  8, 18],\n",
       "         [21, 29, 21,  ...,  8, 18, 29],\n",
       "         [29, 21, 15,  ..., 18, 29,  7],\n",
       "         ...,\n",
       "         [28, 29, 12,  ..., 29, 27, 17],\n",
       "         [29, 12,  8,  ..., 27, 17, 28],\n",
       "         [12,  8, 21,  ..., 17, 28, 25]]),\n",
       " [tensor([5]),\n",
       "  tensor([7]),\n",
       "  tensor([14]),\n",
       "  tensor([7]),\n",
       "  tensor([3]),\n",
       "  tensor([1]),\n",
       "  tensor([2]),\n",
       "  tensor([11]),\n",
       "  tensor([22]),\n",
       "  tensor([3]),\n",
       "  tensor([15]),\n",
       "  tensor([14]),\n",
       "  tensor([12]),\n",
       "  tensor([14]),\n",
       "  tensor([25]),\n",
       "  tensor([2]),\n",
       "  tensor([13]),\n",
       "  tensor([27]),\n",
       "  tensor([16]),\n",
       "  tensor([25]),\n",
       "  tensor([24]),\n",
       "  tensor([16]),\n",
       "  tensor([29]),\n",
       "  tensor([7]),\n",
       "  tensor([28]),\n",
       "  tensor([21]),\n",
       "  tensor([5]),\n",
       "  tensor([19]),\n",
       "  tensor([6]),\n",
       "  tensor([10]),\n",
       "  tensor([17]),\n",
       "  tensor([28])])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(trn_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e11d16",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c7970653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "23d3d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autocorrect(nn.Module):\n",
    "    def __init__(self,num_emb,vs,hs,bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_emb,vs)\n",
    "        self.enc_gru = nn.GRU(vs,hs,num_layers=1,bidirectional=False,batch_first=True,dropout=0.2)\n",
    "        self.dec_gru = nn.GRU(vs,hs,num_layers=1,bidirectional=False,batch_first=True,dropout=0.2)\n",
    "        self.lin = nn.Linear(hs,num_emb)\n",
    "    def forward(self,x):\n",
    "        \n",
    "        bs,seq_len=x.shape\n",
    "        print(bs)\n",
    "        x = self.emb(x)\n",
    "        _,x = self.gru(x)\n",
    "        x = x.permute(1,0,2)\n",
    "        x=x.reshape(32,-1)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.lin(x)\n",
    "        return torch.softmax(x,dim=-1).view(bs*seq_len,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f5fcf1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_emb = len(i2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "125dd843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = autocorrect(num_emb,100,512).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "72bfe6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load available vectors\n",
    "model.emb.weight.requires_grad_(False)\n",
    "for i in i2v.keys():\n",
    "    model.emb.weight[i] = nn.Parameter(torch.from_numpy(i2v[i].copy())).requires_grad_(False)\n",
    "model.emb.weight.requires_grad_(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2982db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ae6875e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(ignore_index=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "51d6170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model,val_dl,trn_dl,loss_fnc):\n",
    "    model.train()\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        for batch in trn_dl:\n",
    "            opt.zero_grad()\n",
    "            ip,label = batch\n",
    "            op = model(ip.cuda())\n",
    "            trn_l = loss_fnc(op,label.view(-1).cuda())\n",
    "            trn_l.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in val_dl:\n",
    "                ip,label = batch\n",
    "                op = model(ip.cuda())\n",
    "                val_loss = loss_fnc(op,label.view(-1).cuda())\n",
    "        print('train_loss ->',trn_l.item() , 'val_loss ->',val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "06e9d8b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.966956377029419 val_loss -> 2.9245524406433105\n",
      "train_loss -> 2.8179426193237305 val_loss -> 2.78366756439209\n",
      "train_loss -> 2.713853597640991 val_loss -> 2.6620876789093018\n",
      "train_loss -> 2.671865463256836 val_loss -> 2.632185459136963\n",
      "train_loss -> 2.6573901176452637 val_loss -> 2.611616373062134\n",
      "train_loss -> 2.6203505992889404 val_loss -> 2.578900098800659\n",
      "train_loss -> 2.6199350357055664 val_loss -> 2.5786995887756348\n",
      "train_loss -> 2.612917900085449 val_loss -> 2.5740554332733154\n",
      "train_loss -> 2.6128077507019043 val_loss -> 2.5739822387695312\n",
      "train_loss -> 2.6127774715423584 val_loss -> 2.5739588737487793\n",
      "train_loss -> 2.563910722732544 val_loss -> 2.573953866958618\n",
      "train_loss -> 2.5590922832489014 val_loss -> 2.5646677017211914\n",
      "train_loss -> 2.559047222137451 val_loss -> 2.5551881790161133\n",
      "train_loss -> 2.558993101119995 val_loss -> 2.5551440715789795\n",
      "train_loss -> 2.556666374206543 val_loss -> 2.5520050525665283\n",
      "train_loss -> 2.5519909858703613 val_loss -> 2.548866033554077\n",
      "train_loss -> 2.551971912384033 val_loss -> 2.5488531589508057\n",
      "train_loss -> 2.5519611835479736 val_loss -> 2.5488479137420654\n",
      "train_loss -> 2.5519556999206543 val_loss -> 2.548844814300537\n",
      "train_loss -> 2.551952600479126 val_loss -> 2.5488433837890625\n",
      "train_loss -> 2.5519490242004395 val_loss -> 2.5488414764404297\n",
      "train_loss -> 2.5507471561431885 val_loss -> 2.5488736629486084\n",
      "train_loss -> 2.5472893714904785 val_loss -> 2.5488500595092773\n",
      "train_loss -> 2.54728364944458 val_loss -> 2.5488438606262207\n",
      "train_loss -> 2.547276735305786 val_loss -> 2.548841953277588\n",
      "train_loss -> 2.547274589538574 val_loss -> 2.548840045928955\n",
      "train_loss -> 2.5472733974456787 val_loss -> 2.5488390922546387\n",
      "train_loss -> 2.5472729206085205 val_loss -> 2.5488381385803223\n",
      "train_loss -> 2.547272205352783 val_loss -> 2.548837423324585\n",
      "train_loss -> 2.547283411026001 val_loss -> 2.5488462448120117\n",
      "train_loss -> 2.547274112701416 val_loss -> 2.5488383769989014\n",
      "train_loss -> 2.547272205352783 val_loss -> 2.548837184906006\n",
      "train_loss -> 2.5480051040649414 val_loss -> 2.54777455329895\n",
      "train_loss -> 2.5472755432128906 val_loss -> 2.5472755432128906\n",
      "train_loss -> 2.5472726821899414 val_loss -> 2.5472726821899414\n",
      "train_loss -> 2.547271728515625 val_loss -> 2.5472710132598877\n",
      "train_loss -> 2.5472707748413086 val_loss -> 2.5472702980041504\n",
      "train_loss -> 2.547269105911255 val_loss -> 2.547269582748413\n",
      "train_loss -> 2.547269105911255 val_loss -> 2.547269344329834\n",
      "train_loss -> 2.547268867492676 val_loss -> 2.547269344329834\n",
      "train_loss -> 2.5472686290740967 val_loss -> 2.5472686290740967\n",
      "train_loss -> 2.5472686290740967 val_loss -> 2.5472683906555176\n",
      "train_loss -> 2.5472686290740967 val_loss -> 2.5472683906555176\n",
      "train_loss -> 2.5472679138183594 val_loss -> 2.5472683906555176\n",
      "train_loss -> 2.5472681522369385 val_loss -> 2.5472681522369385\n",
      "train_loss -> 2.5472679138183594 val_loss -> 2.5472679138183594\n",
      "train_loss -> 2.5472676753997803 val_loss -> 2.5472679138183594\n",
      "train_loss -> 2.5472676753997803 val_loss -> 2.5472679138183594\n",
      "train_loss -> 2.5472676753997803 val_loss -> 2.5472676753997803\n",
      "train_loss -> 2.5472676753997803 val_loss -> 2.5472676753997803\n"
     ]
    }
   ],
   "source": [
    "train(50,model,trn_dl,val_dl,loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae20d15",
   "metadata": {},
   "source": [
    "# Seq to Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d8e04963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "68186343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(txt,ws=15):\n",
    "    ignore = ws-2\n",
    "    txt = list(txt)\n",
    "    grams = ngrams(txt,ws ,pad_left=True,pad_right=True,left_pad_symbol='Q',right_pad_symbol='W')\n",
    "    return list(grams)[ignore:-ignore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "70844b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_grams=[]\n",
    "for txt in msa_data:\n",
    "    ng = get_ngrams(txt)\n",
    "    if ng:\n",
    "        msa_grams.extend(ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "69c54bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(txt):\n",
    "    sz = int(len(txt)*0.2)\n",
    "    noise_sz = np.random.randint(0,sz if sz>1 else 1,1)\n",
    "    replace_idx = np.random.choice(len(txt),noise_sz,replace=False)\n",
    "    letters_idx = np.random.choice(len(i2l)-3,noise_sz,replace=True)\n",
    "    txt = list(txt)\n",
    "    for rep,let in zip(replace_idx,letters_idx):\n",
    "        txt[rep] = i2l[let]\n",
    "    return ''.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bb799d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class arrDs(Dataset):\n",
    "    def __init__(self,txt_list,l2i):\n",
    "        self.data = txt_list\n",
    "        self.l2i = l2i\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        #X = noise(self.data[idx])\n",
    "        X = noise(self.data[idx])\n",
    "        Y = self.data[idx]\n",
    "        \n",
    "        X = torch.tensor([self.l2i.get(i,31) for i in X])\n",
    "        Y = torch.tensor([self.l2i.get(i,31) for i in Y])\n",
    "        #numerilize\n",
    "        return torch.stack([X,Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "14ba0638",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data, val_data = msa_grams[:int(0.8*len(msa_grams))],msa_grams[int(0.8*len(msa_grams)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "928866d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds,val_ds = arrDs(trn_data,l2i),arrDs(val_data,l2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8ff4d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds,batch_size=256,drop_last=False)\n",
    "val_dl = DataLoader(val_ds,batch_size=256,drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70a3246",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fd272f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6165f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autocorrect(nn.Module):\n",
    "    def __init__(self,num_emb,vs,hs,bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.hs = hs\n",
    "        self.emb = nn.Embedding(num_emb,vs)\n",
    "        self.enc_gru = nn.GRU(vs,hs,num_layers=1,bidirectional=False,batch_first=True)\n",
    "        self.dec_gru = nn.GRU(hs,hs,num_layers=1,bidirectional=False,batch_first=True)\n",
    "        self.lin = nn.Sequential(nn.Linear(hs,hs),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(hs,num_emb))\n",
    "    def forward(self,x):\n",
    "        bs,seq_len=x.shape\n",
    "        x = self.emb(x)\n",
    "        #print('emb',x.shape)\n",
    "        x = self.enc_gru(x)\n",
    "        #print('enc',x[0].shape)\n",
    "        op=[]\n",
    "        sos = torch.zeros(bs,1,self.hs).cuda()\n",
    "        h = x[1]\n",
    "        for i in range(15):\n",
    "            sos,h = model.dec_gru(sos,h)\n",
    "            op.append(h.detach())\n",
    "        #    print('h',h.shape)\n",
    "        x = torch.stack(op,dim=1).squeeze().permute(1,0,2)\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        return torch.log_softmax(x,dim=-1).permute(0,2,1).contiguous().view(bs*seq_len,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "46ef0418",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_emb = len(i2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "70ff98ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = autocorrect(num_emb,100,512).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f6c9d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load available vectors\n",
    "model.emb.weight.requires_grad_(False)\n",
    "for i in i2v.keys():\n",
    "    model.emb.weight[i] = nn.Parameter(torch.from_numpy(i2v[i].copy())).requires_grad_(False)\n",
    "model.emb.weight.requires_grad_(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "31089929",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3fedcf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(ignore_index=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "05a27a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model,trn_dl,val_dl,loss_fnc):\n",
    "    model.train()\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        for batch in tqdm.tqdm(trn_dl,'train'):\n",
    "            opt.zero_grad()\n",
    "            ip,label = batch[:,0,:],batch[:,1,:]\n",
    "            op = model(ip.cuda())\n",
    "            trn_l = loss_fnc(op,label.contiguous().view(-1).cuda())\n",
    "            trn_l.backward()\n",
    "            opt.step()\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in tqdm.tqdm(val_dl,'validation'):\n",
    "                ip,label = batch[:,0,:],batch[:,1,:]\n",
    "                op = model(ip.cuda())\n",
    "                val_loss = loss_fnc(op,label.contiguous().view(-1).cuda())\n",
    "        print('train_loss ->',trn_l.item() , 'val_loss ->',val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "366c2fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 993/993 [00:27<00:00, 35.57it/s]\n",
      "validation: 100%|██████████| 249/249 [00:06<00:00, 36.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.8029258251190186 val_loss -> 2.6647675037384033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 993/993 [00:27<00:00, 35.89it/s]\n",
      "validation: 100%|██████████| 249/249 [00:06<00:00, 37.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.6925783157348633 val_loss -> 2.52119779586792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 993/993 [00:27<00:00, 35.64it/s]\n",
      "validation: 100%|██████████| 249/249 [00:06<00:00, 36.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.595806837081909 val_loss -> 2.482649564743042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 993/993 [00:27<00:00, 36.11it/s]\n",
      "validation: 100%|██████████| 249/249 [00:06<00:00, 37.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.5575501918792725 val_loss -> 2.472534418106079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 993/993 [00:27<00:00, 35.61it/s]\n",
      "validation: 100%|██████████| 249/249 [00:06<00:00, 37.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.5475142002105713 val_loss -> 2.416454792022705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 993/993 [00:28<00:00, 35.40it/s]\n",
      "validation: 100%|██████████| 249/249 [00:06<00:00, 37.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.514843463897705 val_loss -> 2.3395650386810303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 993/993 [00:27<00:00, 35.74it/s]\n",
      "validation: 100%|██████████| 249/249 [00:06<00:00, 37.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.460703134536743 val_loss -> 2.3499512672424316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 993/993 [00:27<00:00, 35.61it/s]\n",
      "validation: 100%|██████████| 249/249 [00:06<00:00, 37.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.45233154296875 val_loss -> 2.3488595485687256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 993/993 [00:27<00:00, 35.58it/s]\n",
      "validation: 100%|██████████| 249/249 [00:06<00:00, 36.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.422328472137451 val_loss -> 2.3380918502807617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 993/993 [00:27<00:00, 35.78it/s]\n",
      "validation: 100%|██████████| 249/249 [00:06<00:00, 37.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -> 2.4123878479003906 val_loss -> 2.324697494506836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(10,model,trn_dl,val_dl,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a15d7695",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0ebe1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "eedac3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 2, 15])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c1565646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13, 18,  2,  4,  5, 29, 21,  1, 16, 29,  4,  3, 21, 29,  1],\n",
       "        [13, 29,  2,  4,  5, 29, 21,  1, 16, 29,  4,  3, 20, 29,  1]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "984dbd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29,  4, 29, 29, 29, 29, 29,  4, 29, 29, 21, 21,  4, 29,  1, 29,  4, 29,\n",
       "        29, 29, 29, 29,  4, 29, 29, 20,  4,  4, 29,  1], device='cuda:0')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(d[0].cuda()).argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c35dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5f9b7745",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autocorrect(nn.Module):\n",
    "    def __init__(self,num_emb,vs,hs,bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.hs = hs\n",
    "        self.emb = nn.Embedding(num_emb,vs)\n",
    "        self.lin = nn.Linear(vs,num_emb)\n",
    "    def forward(self,x):\n",
    "        bs,seq_len=x.shape\n",
    "        x = self.emb(x)\n",
    "        #print('emb',x.shape)\n",
    "        x = self.lin(x)\n",
    "        x = torch.softmax(x,dim=-1)\n",
    "        \n",
    "        return x.view(bs*seq_len,-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
